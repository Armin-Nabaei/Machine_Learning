{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image classification with Vision Transformer\n",
        "This example implements for image classification,and demonstrates it on the CIFAR-10 and CIFAR-100 datasetS.\n",
        "The HYBRID MODEL consists of a modified ViT and attentive modules.\n",
        "\n",
        "**!pip install -U tensorflow-addons**\n"
      ],
      "metadata": {
        "id": "Z0dW15yxwZ9F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em_vCIvsWgol"
      },
      "source": [
        "# LIBRARIES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QGAEnuJ8WHd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10,cifar100\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import time\n",
        "from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from __future__ import print_function, division, absolute_import\n",
        "import timeit\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalMaxPooling2D,AveragePooling2D,UpSampling2D,Conv2DTranspose,DepthwiseConv2D,Conv1D,Add\n",
        "from tensorflow.keras.layers import ELU,SeparableConv2D,DepthwiseConv1D\n",
        "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense,ZeroPadding2D,Concatenate,AveragePooling1D\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam,Adadelta,Adamax\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau,LearningRateScheduler\n",
        "from keras.models import load_model\n",
        "import os\n",
        "from PIL import Image\n",
        "import requests\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.activations import *\n",
        "from tensorflow.python.keras.utils.generic_utils import deserialize_keras_object\n",
        "from tensorflow.python.keras.utils.generic_utils import serialize_keras_object\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import nn\n",
        "from numpy.core.fromnumeric import transpose\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load data"
      ],
      "metadata": {
        "id": "ra0K4ju7uU-P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AV9a-EGIaKu"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "AUTO = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmI7dgf3Gr0n"
      },
      "outputs": [],
      "source": [
        "def make_dataset(dataset: tf.data.Dataset, train: bool, image_size: int = 224):\n",
        "    def preprocess(image, label):\n",
        "        if train:\n",
        "            channels = image.shape[-1]\n",
        "            begin, size, _ = tf.image.sample_distorted_bounding_box(\n",
        "                tf.shape(image),\n",
        "                tf.zeros([0, 0, 4], tf.float32),\n",
        "                area_range=(0.05, 1.0),\n",
        "                min_object_covered=0,\n",
        "                use_image_if_no_bounding_boxes=True,\n",
        "            )\n",
        "            image = tf.slice(image, begin, size)\n",
        "\n",
        "            image.set_shape([None, None, channels])\n",
        "            image = tf.image.resize(image, [image_size, image_size])\n",
        "            if tf.random.uniform(shape=[]) > 0.5:\n",
        "                image = tf.image.flip_left_right(image)\n",
        "\n",
        "        else:\n",
        "            image = tf.image.resize(image, [image_size, image_size])\n",
        "\n",
        "        image = (image - 127.5) / 127.5\n",
        "        return image, label\n",
        "\n",
        "    if train:\n",
        "        dataset = dataset.shuffle(BATCH_SIZE * 10)\n",
        "\n",
        "    return dataset.map(preprocess, AUTO).batch(BATCH_SIZE).prefetch(AUTO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clPUF-s9G3md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c097b0-33fa-409f-fb62-48e2e330a897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 160.71 MiB (download: 160.71 MiB, generated: 132.03 MiB, total: 292.74 MiB) to /root/tensorflow_datasets/cifar100/3.0.2...\n",
            "Dataset cifar100 downloaded and prepared to /root/tensorflow_datasets/cifar100/3.0.2. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "train_dataset, val_dataset = tfds.load('cars196', split=['train','test'], as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-zBXdg8H9me",
        "outputId": "87c10f20-be7e-4b5a-8341-fb9f418c884f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 8144\n",
            "Number of validation examples: 8041\n"
          ]
        }
      ],
      "source": [
        "num_train = tf.data.experimental.cardinality(train_dataset)\n",
        "num_val = tf.data.experimental.cardinality(val_dataset)\n",
        "print(f\"Number of training examples: {num_train}\")\n",
        "print(f\"Number of validation examples: {num_val}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvtOJlvRITU6"
      },
      "outputs": [],
      "source": [
        "train_dataset = make_dataset(train_dataset, True)\n",
        "val_dataset = make_dataset(val_dataset, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Labe Encoding"
      ],
      "metadata": {
        "id": "9p71BI9kITx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = tf.cast(y_train,tf.int32)\n",
        "y_test = tf.cast(y_test,tf.int32)\n",
        "y_train = tf.one_hot(y_train,depth=10)\n",
        "y_test = tf.one_hot(y_test, depth=10)\n",
        "y_train = tf.cast(y_train,tf.float32)\n",
        "y_test = tf.cast(y_test,tf.float32)"
      ],
      "metadata": {
        "id": "FSzTfs7SKcPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lr warm up"
      ],
      "metadata": {
        "id": "9iJKlP4OUxTP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmLvpwaCIkUr"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "import random\n",
        "class WarmUpCosine(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(\n",
        "        self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps\n",
        "    ):\n",
        "        super(WarmUpCosine, self).__init__()\n",
        "\n",
        "        self.learning_rate_base = learning_rate_base\n",
        "        self.total_steps = total_steps\n",
        "        self.warmup_learning_rate = warmup_learning_rate\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.pi = tf.constant(np.pi)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        if self.total_steps < self.warmup_steps:\n",
        "            raise ValueError(\"Total_steps must be larger or equal to warmup_steps.\")\n",
        "        learning_rate = (\n",
        "            0.5\n",
        "            * self.learning_rate_base\n",
        "            * (\n",
        "                1\n",
        "                + tf.cos(\n",
        "                    self.pi\n",
        "                    * (tf.cast(step, tf.float32) - self.warmup_steps)\n",
        "                    / float(self.total_steps - self.warmup_steps)\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "        if self.warmup_steps > 0:\n",
        "            if self.learning_rate_base < self.warmup_learning_rate:\n",
        "                raise ValueError(\n",
        "                    \"Learning_rate_base must be larger or equal to \"\n",
        "                    \"warmup_learning_rate.\"\n",
        "                )\n",
        "            slope = (\n",
        "                self.learning_rate_base - self.warmup_learning_rate\n",
        "            ) / self.warmup_steps\n",
        "            warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n",
        "            learning_rate = tf.where(\n",
        "                step < self.warmup_steps, warmup_rate, learning_rate\n",
        "            )\n",
        "        return tf.where(\n",
        "            step > self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n",
        "        )\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "                'learning_rate_base': self.learning_rate_base,\n",
        "                'total_steps': self.total_steps,\n",
        "                'warmup_learning_rate': self.warmup_learning_rate,\n",
        "                'warmup_steps': self.warmup_steps,\n",
        "\n",
        "                 }\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pet4gNehIuAV",
        "outputId": "9f64ce72-07ab-438d-cf2f-ad0c7e3b7fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39062\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "TOTAL_STEPS = int((50000 / BATCH_SIZE) * EPOCHS)\n",
        "WARMUP_STEPS = 10\n",
        "INIT_LR = 0.03\n",
        "WAMRUP_LR = 0.006\n",
        "\n",
        "print(TOTAL_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "IvPpu6HeI0Mp",
        "outputId": "4740062d-4c1c-4306-8dcb-d4fa65a0794e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "scheduled_lrs = WarmUpCosine(\n",
        "    learning_rate_base=INIT_LR,\n",
        "    total_steps=TOTAL_STEPS,\n",
        "    warmup_learning_rate=WAMRUP_LR,\n",
        "    warmup_steps=WARMUP_STEPS,\n",
        ")\n",
        "\n",
        "lrs = [scheduled_lrs(step) for step in range(TOTAL_STEPS)]\n",
        "plt.plot(lrs)\n",
        "plt.xlabel(\"Step\", fontsize=14)\n",
        "plt.ylabel(\"LR\", fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMKcSVz1tItl"
      },
      "source": [
        "# hyperparameter setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBMBuc_D9yyt"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "num_classes=196\n",
        "batch_size = 64\n",
        "num_epochs = 100\n",
        "image_size = 224  # We'll resize input images to this size\n",
        "patch_size = 64 # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers = 2\n",
        "mlp_head_units = [1024,512]  # Size of the dense layers of the final classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pQrnYlUtIto"
      },
      "source": [
        "## data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4Ob6X6ptItp"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "        #layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        #layers.RandomFlip(\"horizontal\"),\n",
        "        #layers.RandomRotation(factor=0.02),\n",
        "        #layers.RandomZoom(\n",
        "         #   height_factor=0.2, width_factor=0.2\n",
        "        #),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9KveLojtItq"
      },
      "source": [
        "## Implement multilayer perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVShQ_4XtItq"
      },
      "outputs": [],
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcOq3beitItv"
      },
      "source": [
        "## patch encoding layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAFgXj74VOvl"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"SAME\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "##############\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        ) #produce a table to map inputs to embedding vectors\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaR5YSPftItw"
      },
      "source": [
        "# Bottlneck_Channelmix Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3cvCNX_PQwX"
      },
      "outputs": [],
      "source": [
        "def channel_mix(l,imgs):\n",
        "\n",
        "    channel_r=imgs[:,:,0:1]\n",
        "    channel_g=imgs[:,:,1:2]\n",
        "    channel_b=imgs[:,:,2:3]\n",
        "\n",
        "    channel1_r=l[:,:,0:21]\n",
        "    channel1_g=l[:,:,21:41]\n",
        "    channel1_b=l[:,:,43:63]\n",
        "\n",
        "    l1 = tf.concat([channel1_r, channel_r],axis=2)\n",
        "    l2 = tf.concat([channel1_g, channel_g],axis=2)\n",
        "    l3 = tf.concat([channel1_b, channel_b],axis=2)\n",
        "\n",
        "    l = tf.concat([l1,l2,l3],axis=2)\n",
        "\n",
        "    return l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inb_AvviE3YS"
      },
      "outputs": [],
      "source": [
        "\n",
        "def bottleneck(input,layers):\n",
        "    for _ in range(layers):\n",
        "        print(\"INPUT SHAPE\",input.shape)\n",
        "        x=Conv1D(64, 5, padding = \"same\", kernel_initializer=\"he_normal\")(input)\n",
        "        x=Activation('elu')(x)\n",
        "        print(\"First CONV SHAPE \",x.shape)\n",
        "        x2= DepthwiseConv1D( 1, padding = 'same', kernel_initializer=\"he_normal\",depth_multiplier=2)(input)\n",
        "        print(\"input increased dimension Shape\",x2.shape)\n",
        "        x = Add()([input,x])\n",
        "        x=Conv1D(64, 1, padding = \"same\", groups=4 , kernel_initializer=\"he_normal\")(x)\n",
        "        x=Activation('elu')(x)\n",
        "        print(\"Decreased dimension shape\",x.shape)\n",
        "        x= channel_mix (x, input)\n",
        "        print(\"OUTPUT x SHAPE\",x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEz4wIBMPNcP"
      },
      "outputs": [],
      "source": [
        "#@under_name_scope()\n",
        "def channel_shuffle(l, group):\n",
        "    in_shape = l.get_shape().as_list()\n",
        "    in_channel = in_shape[2]\n",
        "    assert in_channel % group == 0, in_channel\n",
        "    l = tf.reshape(l, [-1, in_channel // group, group] + in_shape[-1:])\n",
        "    l = tf.transpose(l, [0, 2, 1, 3])\n",
        "    l = tf.reshape(l, [-1, in_channel] + in_shape[-1:])\n",
        "    print('shuffle output',l.shape)\n",
        "    return l\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTSK0diR1VBv"
      },
      "outputs": [],
      "source": [
        "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "inception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "handle=\"https://tfhub.dev/sayakpaul/vit_s16_fe/1\"\n",
        "b1_vit=\"https://tfhub.dev/sayakpaul/vit_b8_classification/1\"\n",
        "mixer_1 = \"https://tfhub.dev/sayakpaul/mixer_b16_sam_classification/1\"\n",
        "feature_extractor_model = mixer_1\n",
        "mixer_2 = \"https://tfhub.dev/sayakpaul/mixer_b16_sam_fe/1\"\n",
        "feature_extractor_model2 = mixer_2\n",
        "#https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\n",
        "feature_3 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "feature_extractor_model3 = feature_3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modified Vit"
      ],
      "metadata": {
        "id": "LIqpvjSCiHhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_primary = layers.Input(shape=(224,224, 3))\n",
        "\n",
        "inputs_vit_rescaled=rescale_layer_vit (inputs_primary)\n",
        "inputs_vit_resized = rescale_resize_vit (inputs_vit_rescaled)\n",
        "print (inputs_vit_resized.shape)\n",
        "input_augmented_vit = data_augmentation_vit (inputs_vit_resized)\n",
        "\n",
        "#################################\n",
        "\n",
        "mixer_3 = \"https://tfhub.dev/sayakpaul/vit_b8_classification/1\"\n",
        "feature_extractor_model2 = mixer_3\n",
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_model2,input_shape=(224,224 ,3),trainable=False)\n",
        "augmented1 = feature_extractor_layer(input_augmented_vit)\n",
        "print('feature_extractor output:',augmented1.shape)\n",
        "augmented12 = tf.expand_dims(augmented1, axis=1)\n",
        "print('12:',augmented12.shape)\n",
        "augmented13 = tf.expand_dims(augmented12, axis=2)\n",
        "print('13:',augmented13.shape)\n",
        "#######################################################\n",
        "# Create patches.\n",
        "patches = Patches(patch_size)(augmented13)\n",
        "# Encode patches.\n",
        "print(' patches:',patches.shape)\n",
        "encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "print(' encoded_patches output :',encoded_patches.shape)\n",
        "\n",
        "for _ in range(transformer_layers):\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=projection_dim, dropout=0.0\n",
        "    )(encoded_patches, encoded_patches)\n",
        "\n",
        "    # Bottlneck for odd layers\n",
        "    if _  <= (1):\n",
        "       attention_output = bottleneck(attention_output,1)\n",
        "\n",
        "    # Skip connection 1.\n",
        "    x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "    # MLP.\n",
        "    x3 = mlp(x2, hidden_units=transformer_units, dropout_rate=0.0)\n",
        "\n",
        "    # Skip connection 2.\n",
        "    encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    ##################\n",
        "representation2 = layers.Flatten()(encoded_patches)\n",
        "representation = layers.Dropout(0.2)(representation2)\n",
        "model_vit = Model(inputs=inputs_primary, outputs=representation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdDiVccYiQ67",
        "outputId": "e60e015c-cbdf-41b9-b2f8-1b13110bfe93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 3)\n",
            "feature_extractor output: (None, 1000)\n",
            "12: (None, 1, 1000)\n",
            "13: (None, 1, 1, 1000)\n",
            " patches: (None, None, 4096000)\n",
            " encoded_patches output : (None, 9, 64)\n",
            "INPUT SHAPE (None, 9, 64)\n",
            "First CONV SHAPE  (None, 9, 64)\n",
            "input increased dimension Shape (None, 9, 128)\n",
            "Decreased dimension shape (None, 9, 64)\n",
            "OUTPUT x SHAPE (None, 9, 64)\n",
            "INPUT SHAPE (None, 9, 64)\n",
            "First CONV SHAPE  (None, 9, 64)\n",
            "input increased dimension Shape (None, 9, 128)\n",
            "Decreased dimension shape (None, 9, 64)\n",
            "OUTPUT x SHAPE (None, 9, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Module 1"
      ],
      "metadata": {
        "id": "B79pvsRbirs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 0\n",
        "inputs_primary = layers.Input(shape=(32,32, 3))\n",
        "##########\n",
        "inputs_cnn_rescaled=rescale_layer_cnn (inputs_primary)\n",
        "inputs_cnn_resized = rescale_resize_cnn (inputs_cnn_rescaled)\n",
        "print (inputs_cnn_resized.shape)\n",
        "input_augmented_cnn = data_augmentation_cnn (inputs_cnn_resized)\n",
        "###################################################################\n",
        "mixer_32 = \"https://tfhub.dev/sayakpaul/vit_b8_classification/1\"\n",
        "feature_extractor_model3 = mixer_32\n",
        "feature_extractor_layer2 = hub.KerasLayer(feature_extractor_model3,input_shape=(224,224 ,3),trainable=False)\n",
        "augmented123 = feature_extractor_layer2(input_augmented_cnn)\n",
        "print('feature_extractor out:',augmented123.shape)\n",
        "#############\n",
        "augmented123=tf.expand_dims(augmented123,axis=2)\n",
        "ave1 = AveragePooling1D(pool_size=(2), padding='valid', strides=2, name='Avg_pool_1')(augmented123)\n",
        "print('pool first',ave1.shape)\n",
        "ave2 = AveragePooling1D(pool_size=(3), padding='valid', strides=3, name='Avg_pool_2')(augmented123)\n",
        "print('pool second',ave2.shape)\n",
        "ave3 = AveragePooling1D(pool_size=(5), padding='valid', strides=5, name='Avg_pool_3')(augmented123)\n",
        "print('pool third',ave3.shape)\n",
        "ave_concate = Concatenate(axis=1) ([ave1,ave2,ave3])\n",
        "print('ave_pool concate',ave_concate.shape)\n",
        "max1 = AveragePooling1D(pool_size=(2), padding='valid', strides=2, name='max_pool_1')(augmented123)\n",
        "print('max first',max1.shape)\n",
        "max2 = AveragePooling1D(pool_size=(3), padding='valid', strides=3, name='max_pool_2')(augmented123)\n",
        "print('max second',max2.shape)\n",
        "max3 = AveragePooling1D(pool_size=(5), padding='valid', strides=5, name='max_pool_3')(augmented123)\n",
        "print('max third',max3.shape)\n",
        "max_concate = Concatenate(axis=1) ([max1,max2,max3])\n",
        "print('max_pool concate',ave_concate.shape)\n",
        "pool_con= Concatenate(axis=1) ([max_concate,ave_concate])\n",
        "print('pool concate',pool_con.shape)\n",
        "pool_flattend = Flatten()(pool_con)\n",
        "print('pool flattend',pool_flattend.shape)\n",
        "#####################################################################\n",
        "s0, s1 = tf.split(pool_flattend, num_or_size_splits=2, axis=1)\n",
        "print('split shape:',s0.shape)\n",
        "a1=  tf.stack([s0, s1], axis=1)\n",
        "print('concate shape:',a1.shape)\n",
        "####################################\n",
        "input_dec=Conv1D(500, (1), padding = \"same\", kernel_initializer=\"he_normal\",name='decrease_dimension_1')(a1)\n",
        "x1_branch=Conv1D(500, (3), padding = \"same\", kernel_initializer=\"he_normal\",name='conv2D_1_module_1')(a1)\n",
        "x1_branch=BatchNormalization()(x1_branch)\n",
        "x1_branch_out = Activation(\"softmax\", dtype=tf.float32, name=\"softmax_module_1\")(x1_branch)\n",
        "x1_out = tf.math.multiply(input_dec, x1_branch_out)\n",
        "####################################\n",
        "x2_branch=Conv1D(250, (1), padding = \"same\", kernel_initializer=\"he_normal\",name='conv2D_2_module_1')(x1_out)\n",
        "print(x2_branch.shape)\n",
        "x2_branch=BatchNormalization()(x2_branch)\n",
        "x2_branch=Activation('elu')(x2_branch)\n",
        "x2_branch=DepthwiseConv1D(250, (1),padding='same', depth_multiplier=2, kernel_initializer=\"he_normal\",name='conv2D_3_module_1')(x2_branch)\n",
        "print(x2_branch.shape)\n",
        "##########################\n",
        "x2_out = x2_branch\n",
        "z= tf.math.multiply(input_dec, x2_out)\n",
        "model_1 = Model(inputs_primary, outputs=z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33LwsmImiuHZ",
        "outputId": "35ce54f3-b6a3-4beb-d909-74e29c4954d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 3)\n",
            "feature_extractor out: (None, 1000)\n",
            "pool first (None, 500, 1)\n",
            "pool second (None, 333, 1)\n",
            "pool third (None, 200, 1)\n",
            "ave_pool concate (None, 1033, 1)\n",
            "max first (None, 500, 1)\n",
            "max second (None, 333, 1)\n",
            "max third (None, 200, 1)\n",
            "max_pool concate (None, 1033, 1)\n",
            "pool concate (None, 2066, 1)\n",
            "pool flattend (None, 2066)\n",
            "split shape: (None, 1033)\n",
            "concate shape: (None, 2, 1033)\n",
            "(None, 2, 250)\n",
            "(None, 2, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Module 2"
      ],
      "metadata": {
        "id": "c5S6rz0Aogt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_primary = layers.Input(shape=(32,32, 3))\n",
        "##########\n",
        "inputs_cnn_rescaled=rescale_layer_cnn (inputs_primary)\n",
        "inputs_cnn_resized = rescale_resize_cnn (inputs_cnn_rescaled)\n",
        "print (inputs_cnn_resized.shape)\n",
        "mixer_35 = \"https://tfhub.dev/sayakpaul/vit_b8_classification/1\"\n",
        "feature_extractor_model5 = mixer_35\n",
        "feature_extractor_layer4 = hub.KerasLayer(feature_extractor_model5,input_shape=(224,224 ,3),trainable=False)\n",
        "x_resi2 = feature_extractor_layer4(inputs_cnn_resized)\n",
        "x_resi2=tf.dtypes.cast(x_resi2,tf.float32)\n",
        "model_helper_1 = Model(inputs=inputs_primary, outputs=x_resi2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvJNdNTvojZk",
        "outputId": "9a9690bf-f315-4111-f22d-c3e8f7eeb5dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Module 3"
      ],
      "metadata": {
        "id": "DJy1pvBqovBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_primary = layers.Input(shape=(32,32, 3))\n",
        "\n",
        "inputs_vit_rescaled=rescale_layer_vit (inputs_primary)\n",
        "inputs_vit_resized = rescale_resize_vit (inputs_vit_rescaled)\n",
        "print (inputs_vit_resized.shape)\n",
        "mixer_34 = \"https://tfhub.dev/sayakpaul/vit_b8_classification/1\"\n",
        "feature_extractor_model4 = mixer_34\n",
        "feature_extractor_layer3 = hub.KerasLayer(feature_extractor_model4,input_shape=(224,224 ,3),trainable=False)\n",
        "x_resi2 = feature_extractor_layer3(inputs_vit_resized)\n",
        "x_resi2=tf.dtypes.cast(x_resi2,tf.float32)\n",
        "model_helper_2 = Model(inputs=inputs_primary, outputs=x_resi2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX5CEASio0dp",
        "outputId": "5a4473bf-c9ad-47de-81a7-a21cbdc304f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Model"
      ],
      "metadata": {
        "id": "p-JmQby_jm2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [model_1,model_vit,model_helper_1,model_helper_2]\n",
        "\n",
        "inputs_primary = layers.Input(shape=(32,32, 3))\n",
        "model_1 = [model(inputs_primary) for model in models[0:1]]\n",
        "model_vit = [model(inputs_primary) for model in models[1:2]]\n",
        "model_helper_1 = [model(inputs_primary) for model in models[2:3]]\n",
        "model_helper_2 = [model(inputs_primary) for model in models[3:4]]\n",
        "\n",
        "x3c = tf.squeeze(model_helper_1, axis=[0])\n",
        "x3c=tf.dtypes.cast(x3c,tf.float32)\n",
        "x3c = Flatten()(x3c)\n",
        "model_helper_1_out=tf.dtypes.cast(x3c,tf.float32)\n",
        "x3 = tf.squeeze(model_1, axis=[0])\n",
        "x3=tf.dtypes.cast(x3,tf.float32)\n",
        "x3 = Flatten()(x3)\n",
        "model_cnn_out=tf.dtypes.cast(x3,tf.float32)\n",
        "model_cnn_out_concatenate = Concatenate(axis=-1) ([model_cnn_out,model_helper_1_out])\n",
        "x2qx = Dense(64, activation='elu',name='dense2w')(model_cnn_out_concatenate)\n",
        "x3qx =BatchNormalization()(x2qx)\n",
        "x4qx = Dropout(0.2)(x3qx)\n",
        "x_1qx = Dense(32, activation='elu',name='dense1w')(x4qx)\n",
        "x_qx =BatchNormalization()(x_1qx)\n",
        "xq = Dropout(0.2)(x_qx)\n",
        "x_out = Dense(num_classes, dtype=tf.float32)(xq)\n",
        "x72wx = Activation(\"softmax\",name='model0')(x_out)\n",
        "##################################################################\n",
        "x3a = tf.squeeze(model_1, axis=[0])\n",
        "x3a=tf.dtypes.cast(x3a,tf.float32)\n",
        "x3a = Flatten()(x3a)\n",
        "model_cnn_outa=tf.dtypes.cast(x3a,tf.float32)\n",
        "model_cnn_out_concatenatea = Concatenate(axis=-1) ([model_cnn_out,model_helper_1_out])\n",
        "model_cnn_out_concatenatea = Flatten() (model_cnn_out_concatenatea)\n",
        "x2qxa = Dense(128, activation='elu',name='dense2w')(model_cnn_out_concatenatea)\n",
        "x3qxa =BatchNormalization()(x2qx)\n",
        "x4qxa = Dropout(0.2)(x3qx)\n",
        "x7_1qxa = Dense(64, activation='elu',name='dense1w')(x4qxa)\n",
        "x7_2qxa =BatchNormalization()(x7_1qxa)\n",
        "x7qxa = Dropout(0.2)(x7_2qxa)\n",
        "x71wxa = Dense(num_classes, dtype=tf.float32)(x7qxa)\n",
        "x72wxa = Activation(\"softmax\",name='model2')(x71wxa)\n",
        "######Model helper 2\n",
        "x3v = tf.squeeze(model_helper_2, axis=[0])\n",
        "x3v=tf.dtypes.cast(x3v,tf.float32)\n",
        "x3v = Flatten()(x3v)\n",
        "model_helper_2_out=tf.dtypes.cast(x3v,tf.float32)\n",
        "#################################\n",
        "x3v = tf.squeeze(model_vit, axis=[0])\n",
        "x3v=tf.dtypes.cast(x3v,tf.float32)\n",
        "x3v = Flatten()(x3v)\n",
        "model_vit_out=tf.dtypes.cast(x3,tf.float32)\n",
        "model_vit_out_concatenate = Concatenate(axis=-1) ([model_vit_out,model_helper_2_out])\n",
        "model_vit_out_concatenate = Flatten()(model_vit_out_concatenate)\n",
        "x2 = Dense(64, activation='elu',name='dense_vit11')(model_vit_out_concatenate)\n",
        "x3 =BatchNormalization()(x2)\n",
        "x4v = Dropout(0.2)(x3)\n",
        "x2v = Dense(32, activation='elu',name='dense_vit12')(x4v)\n",
        "x3v =BatchNormalization()(x2v)\n",
        "x4v = Dropout(0.2)(x3v)\n",
        "x_v81 = layers.Dense(num_classes)(x4v)\n",
        "x_v8 = Activation(\"softmax\",name='vit')(x_v81)\n",
        "#########################################\n",
        "avr= tf.keras.layers.Average(name='average')([x_v8,x72wx])\n",
        "model_final = Model(inputs=inputs_primary, outputs=[x_v8,x72wx,avr])"
      ],
      "metadata": {
        "id": "Ai9gyek1jpWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyNvEJ_dL0v2"
      },
      "source": [
        "# Callback function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZukQsdxEXlb",
        "outputId": "3441116b-e47b-4ce8-e8fe-faec8fdb0dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub/ENSEMBLE Vit_Cnn_CIFAR10_Exp Apr20/20231209-000433\n"
          ]
        }
      ],
      "source": [
        "# Create tensorboard callback\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "#############################\n",
        "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                                  patience=3)\n",
        "# Creating learning rate reduction callback\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
        "                                                 patience=2,\n",
        "                                                 verbose=1, #\n",
        "                                                 min_lr=1e-7)\n",
        "\n",
        "def decay(epochs, steps=100):\n",
        "    initial_lrate = 0.0001\n",
        "    drop = 0.96\n",
        "    epochs_drop = 8\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+(2*epochs)/epochs_drop)))\n",
        "    return lrate\n",
        "################################\n",
        "save_dir = os.path.join(os.getcwd(), \"/save_model\")\n",
        "filepath = \"vit_cnn_20apr.{epoch:02d}-{val_model0_accuracy:.4f}.tf\"\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(save_dir, filepath),\n",
        "                             monitor=\"val_model0_accuracy\",\n",
        "                             save_best_only=True,\n",
        "                             mode=\"max\",\n",
        "                             verbose=0)\n",
        "##############################\n",
        "lr_sc = LearningRateScheduler(decay,verbose=1)\n",
        "mycallback = [early_stopping,lr_sc,reduce_lr,\n",
        "              create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "              experiment_name=\"ENSEMBLE Vit_Cnn_CIFAR10_Exp Apr20\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN"
      ],
      "metadata": {
        "id": "_gTra8G3u9JE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Donload weights from  [link text](https://drive.google.com/file/d/1Bn1DEB7KqOCSBmu2e0HyMW99GXfPYy92/view?usp=sharing)"
      ],
      "metadata": {
        "id": "0vO8nyEW7KFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_final.load_weights(\"vitensemble_5_1.h5\",by_name=True)#"
      ],
      "metadata": {
        "id": "JUk4DxWV6E4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile & Train"
      ],
      "metadata": {
        "id": "yz8o51lx7ViI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxbbZVFPgxH4",
        "outputId": "17b8ab8a-6584-4851-d9a2-6cb08f6991bd"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
            "Layer Patches has arguments ['self', 'patch_size']\n",
            "in `__init__` and therefore must override `get_config()`.\n",
            "\n",
            "Example:\n",
            "\n",
            "class CustomLayer(keras.layers.Layer):\n",
            "    def __init__(self, arg1, arg2):\n",
            "        super().__init__()\n",
            "        self.arg1 = arg1\n",
            "        self.arg2 = arg2\n",
            "\n",
            "    def get_config(self):\n",
            "        config = super().get_config()\n",
            "        config.update({\n",
            "            \"arg1\": self.arg1,\n",
            "            \"arg2\": self.arg2,\n",
            "        })\n",
            "        return config\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
            "Layer Patches has arguments ['self', 'patch_size']\n",
            "in `__init__` and therefore must override `get_config()`.\n",
            "\n",
            "Example:\n",
            "\n",
            "class CustomLayer(keras.layers.Layer):\n",
            "    def __init__(self, arg1, arg2):\n",
            "        super().__init__()\n",
            "        self.arg1 = arg1\n",
            "        self.arg2 = arg2\n",
            "\n",
            "    def get_config(self):\n",
            "        config = super().get_config()\n",
            "        config.update({\n",
            "            \"arg1\": self.arg1,\n",
            "            \"arg2\": self.arg2,\n",
            "        })\n",
            "        return config\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/90\n",
            "782/782 [==============================] - 1214s 1s/step - loss: 10.0190 - vit_loss: 2.3351 - model0_loss: 2.3590 - average_loss: 1.9168 - vit_accuracy: 0.4714 - model0_accuracy: 0.4372 - average_accuracy: 0.5200 - val_loss: 3.6522 - val_vit_loss: 0.9100 - val_model0_loss: 0.9293 - val_average_loss: 0.6822 - val_vit_accuracy: 0.7663 - val_model0_accuracy: 0.7477 - val_average_accuracy: 0.8118\n",
            "Epoch 2/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 7.9862 - vit_loss: 1.8363 - model0_loss: 1.7755 - average_loss: 1.5481 - vit_accuracy: 0.5457 - model0_accuracy: 0.5483 - average_accuracy: 0.6013 - val_loss: 3.0955 - val_vit_loss: 0.8027 - val_model0_loss: 0.7356 - val_average_loss: 0.5849 - val_vit_accuracy: 0.7849 - val_model0_accuracy: 0.7990 - val_average_accuracy: 0.8330\n",
            "Epoch 3/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 7.5512 - vit_loss: 1.7425 - model0_loss: 1.6601 - average_loss: 1.4666 - vit_accuracy: 0.5628 - model0_accuracy: 0.5802 - average_accuracy: 0.6224 - val_loss: 2.8381 - val_vit_loss: 0.7681 - val_model0_loss: 0.6456 - val_average_loss: 0.5389 - val_vit_accuracy: 0.7901 - val_model0_accuracy: 0.8177 - val_average_accuracy: 0.8464\n",
            "Epoch 4/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 7.2943 - vit_loss: 1.6810 - model0_loss: 1.6037 - average_loss: 1.4169 - vit_accuracy: 0.5758 - model0_accuracy: 0.5932 - average_accuracy: 0.6341 - val_loss: 2.7603 - val_vit_loss: 0.7454 - val_model0_loss: 0.6134 - val_average_loss: 0.5268 - val_vit_accuracy: 0.7985 - val_model0_accuracy: 0.8258 - val_average_accuracy: 0.8502\n",
            "Epoch 5/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 7.0824 - vit_loss: 1.6504 - model0_loss: 1.5539 - average_loss: 1.3749 - vit_accuracy: 0.5856 - model0_accuracy: 0.6053 - average_accuracy: 0.6429 - val_loss: 2.6672 - val_vit_loss: 0.7244 - val_model0_loss: 0.6127 - val_average_loss: 0.5052 - val_vit_accuracy: 0.8032 - val_model0_accuracy: 0.8349 - val_average_accuracy: 0.8595\n",
            "Epoch 6/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 7.0324 - vit_loss: 1.6366 - model0_loss: 1.5339 - average_loss: 1.3669 - vit_accuracy: 0.5858 - model0_accuracy: 0.6100 - average_accuracy: 0.6466 - val_loss: 2.5747 - val_vit_loss: 0.6814 - val_model0_loss: 0.5899 - val_average_loss: 0.4893 - val_vit_accuracy: 0.8110 - val_model0_accuracy: 0.8411 - val_average_accuracy: 0.8613\n",
            "Epoch 7/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 6.9260 - vit_loss: 1.6139 - model0_loss: 1.5162 - average_loss: 1.3451 - vit_accuracy: 0.5950 - model0_accuracy: 0.6145 - average_accuracy: 0.6514 - val_loss: 2.5001 - val_vit_loss: 0.6855 - val_model0_loss: 0.5712 - val_average_loss: 0.4737 - val_vit_accuracy: 0.8121 - val_model0_accuracy: 0.8467 - val_average_accuracy: 0.8698\n",
            "Epoch 8/90\n",
            "782/782 [==============================] - 1139s 1s/step - loss: 6.8483 - vit_loss: 1.5918 - model0_loss: 1.5019 - average_loss: 1.3298 - vit_accuracy: 0.5960 - model0_accuracy: 0.6199 - average_accuracy: 0.6550 - val_loss: 2.5238 - val_vit_loss: 0.6882 - val_model0_loss: 0.5878 - val_average_loss: 0.4765 - val_vit_accuracy: 0.8173 - val_model0_accuracy: 0.8387 - val_average_accuracy: 0.8661\n",
            "Epoch 9/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 6.7198 - vit_loss: 1.5667 - model0_loss: 1.4722 - average_loss: 1.3048 - vit_accuracy: 0.6004 - model0_accuracy: 0.6237 - average_accuracy: 0.6603 - val_loss: 2.4670 - val_vit_loss: 0.6750 - val_model0_loss: 0.5561 - val_average_loss: 0.4688 - val_vit_accuracy: 0.8172 - val_model0_accuracy: 0.8451 - val_average_accuracy: 0.8664\n",
            "Epoch 10/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 6.7000 - vit_loss: 1.5670 - model0_loss: 1.4644 - average_loss: 1.3012 - vit_accuracy: 0.6033 - model0_accuracy: 0.6285 - average_accuracy: 0.6620 - val_loss: 2.3795 - val_vit_loss: 0.6668 - val_model0_loss: 0.5360 - val_average_loss: 0.4511 - val_vit_accuracy: 0.8236 - val_model0_accuracy: 0.8540 - val_average_accuracy: 0.8734\n",
            "Epoch 11/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 6.6346 - vit_loss: 1.5522 - model0_loss: 1.4488 - average_loss: 1.2887 - vit_accuracy: 0.6074 - model0_accuracy: 0.6301 - average_accuracy: 0.6651 - val_loss: 2.4067 - val_vit_loss: 0.6527 - val_model0_loss: 0.5458 - val_average_loss: 0.4572 - val_vit_accuracy: 0.8253 - val_model0_accuracy: 0.8494 - val_average_accuracy: 0.8708\n",
            "Epoch 12/90\n",
            "782/782 [==============================] - 1139s 1s/step - loss: 6.5696 - vit_loss: 1.5368 - model0_loss: 1.4369 - average_loss: 1.2757 - vit_accuracy: 0.6082 - model0_accuracy: 0.6339 - average_accuracy: 0.6690 - val_loss: 2.3876 - val_vit_loss: 0.6656 - val_model0_loss: 0.5343 - val_average_loss: 0.4535 - val_vit_accuracy: 0.8233 - val_model0_accuracy: 0.8519 - val_average_accuracy: 0.8736\n",
            "Epoch 13/90\n",
            "782/782 [==============================] - 1139s 1s/step - loss: 6.5386 - vit_loss: 1.5277 - model0_loss: 1.4300 - average_loss: 1.2698 - vit_accuracy: 0.6139 - model0_accuracy: 0.6354 - average_accuracy: 0.6704 - val_loss: 2.3305 - val_vit_loss: 0.6510 - val_model0_loss: 0.5216 - val_average_loss: 0.4425 - val_vit_accuracy: 0.8269 - val_model0_accuracy: 0.8537 - val_average_accuracy: 0.8768\n",
            "Epoch 14/90\n",
            "782/782 [==============================] - 1139s 1s/step - loss: 6.5125 - vit_loss: 1.5230 - model0_loss: 1.4271 - average_loss: 1.2642 - vit_accuracy: 0.6149 - model0_accuracy: 0.6382 - average_accuracy: 0.6705 - val_loss: 2.3220 - val_vit_loss: 0.6503 - val_model0_loss: 0.5358 - val_average_loss: 0.4380 - val_vit_accuracy: 0.8290 - val_model0_accuracy: 0.8527 - val_average_accuracy: 0.8750\n",
            "Epoch 15/90\n",
            "782/782 [==============================] - 1139s 1s/step - loss: 6.3866 - vit_loss: 1.4987 - model0_loss: 1.4043 - average_loss: 1.2385 - vit_accuracy: 0.6209 - model0_accuracy: 0.6435 - average_accuracy: 0.6791 - val_loss: 2.2421 - val_vit_loss: 0.6386 - val_model0_loss: 0.5048 - val_average_loss: 0.4243 - val_vit_accuracy: 0.8297 - val_model0_accuracy: 0.8608 - val_average_accuracy: 0.8795\n",
            "Epoch 16/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 6.3951 - vit_loss: 1.4962 - model0_loss: 1.3997 - average_loss: 1.2416 - vit_accuracy: 0.6220 - model0_accuracy: 0.6420 - average_accuracy: 0.6771 - val_loss: 2.2543 - val_vit_loss: 0.6510 - val_model0_loss: 0.5092 - val_average_loss: 0.4256 - val_vit_accuracy: 0.8329 - val_model0_accuracy: 0.8596 - val_average_accuracy: 0.8790\n",
            "Epoch 17/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 6.3992 - vit_loss: 1.5042 - model0_loss: 1.4015 - average_loss: 1.2417 - vit_accuracy: 0.6185 - model0_accuracy: 0.6439 - average_accuracy: 0.6777 - val_loss: 2.2667 - val_vit_loss: 0.6462 - val_model0_loss: 0.5029 - val_average_loss: 0.4302 - val_vit_accuracy: 0.8288 - val_model0_accuracy: 0.8610 - val_average_accuracy: 0.8792\n",
            "Epoch 18/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 6.3393 - vit_loss: 1.4881 - model0_loss: 1.3970 - average_loss: 1.2287 - vit_accuracy: 0.6240 - model0_accuracy: 0.6462 - average_accuracy: 0.6799 - val_loss: 2.2772 - val_vit_loss: 0.6467 - val_model0_loss: 0.5153 - val_average_loss: 0.4306 - val_vit_accuracy: 0.8350 - val_model0_accuracy: 0.8604 - val_average_accuracy: 0.8794\n",
            "Epoch 19/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 6.2337 - vit_loss: 1.4686 - model0_loss: 1.3701 - average_loss: 1.2085 - vit_accuracy: 0.6291 - model0_accuracy: 0.6492 - average_accuracy: 0.6842 - val_loss: 2.2111 - val_vit_loss: 0.6433 - val_model0_loss: 0.4930 - val_average_loss: 0.4183 - val_vit_accuracy: 0.8309 - val_model0_accuracy: 0.8673 - val_average_accuracy: 0.8798\n",
            "Epoch 20/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 6.2737 - vit_loss: 1.4714 - model0_loss: 1.3759 - average_loss: 1.2173 - vit_accuracy: 0.6250 - model0_accuracy: 0.6486 - average_accuracy: 0.6822 - val_loss: 2.2359 - val_vit_loss: 0.6273 - val_model0_loss: 0.5087 - val_average_loss: 0.4229 - val_vit_accuracy: 0.8341 - val_model0_accuracy: 0.8642 - val_average_accuracy: 0.8812\n",
            "Epoch 21/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 6.2133 - vit_loss: 1.4635 - model0_loss: 1.3680 - average_loss: 1.2042 - vit_accuracy: 0.6296 - model0_accuracy: 0.6533 - average_accuracy: 0.6856 - val_loss: 2.2102 - val_vit_loss: 0.6497 - val_model0_loss: 0.4953 - val_average_loss: 0.4172 - val_vit_accuracy: 0.8355 - val_model0_accuracy: 0.8648 - val_average_accuracy: 0.8824\n",
            "Epoch 22/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 6.1450 - vit_loss: 1.4422 - model0_loss: 1.3548 - average_loss: 1.1910 - vit_accuracy: 0.6341 - model0_accuracy: 0.6552 - average_accuracy: 0.6910 - val_loss: 2.2377 - val_vit_loss: 0.6350 - val_model0_loss: 0.5163 - val_average_loss: 0.4214 - val_vit_accuracy: 0.8308 - val_model0_accuracy: 0.8639 - val_average_accuracy: 0.8803\n",
            "Epoch 23/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 6.1071 - vit_loss: 1.4432 - model0_loss: 1.3431 - average_loss: 1.1835 - vit_accuracy: 0.6345 - model0_accuracy: 0.6560 - average_accuracy: 0.6927 - val_loss: 2.2013 - val_vit_loss: 0.6453 - val_model0_loss: 0.5017 - val_average_loss: 0.4141 - val_vit_accuracy: 0.8358 - val_model0_accuracy: 0.8698 - val_average_accuracy: 0.8861\n",
            "Epoch 24/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 6.1028 - vit_loss: 1.4421 - model0_loss: 1.3386 - average_loss: 1.1833 - vit_accuracy: 0.6348 - model0_accuracy: 0.6586 - average_accuracy: 0.6919 - val_loss: 2.1999 - val_vit_loss: 0.6208 - val_model0_loss: 0.5092 - val_average_loss: 0.4143 - val_vit_accuracy: 0.8379 - val_model0_accuracy: 0.8652 - val_average_accuracy: 0.8853\n",
            "Epoch 25/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 6.0523 - vit_loss: 1.4252 - model0_loss: 1.3338 - average_loss: 1.1728 - vit_accuracy: 0.6384 - model0_accuracy: 0.6597 - average_accuracy: 0.6931 - val_loss: 2.1629 - val_vit_loss: 0.6316 - val_model0_loss: 0.4861 - val_average_loss: 0.4083 - val_vit_accuracy: 0.8384 - val_model0_accuracy: 0.8679 - val_average_accuracy: 0.8859\n",
            "Epoch 26/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.9933 - vit_loss: 1.4140 - model0_loss: 1.3208 - average_loss: 1.1611 - vit_accuracy: 0.6402 - model0_accuracy: 0.6625 - average_accuracy: 0.6954 - val_loss: 2.1696 - val_vit_loss: 0.6371 - val_model0_loss: 0.4895 - val_average_loss: 0.4090 - val_vit_accuracy: 0.8362 - val_model0_accuracy: 0.8662 - val_average_accuracy: 0.8810\n",
            "Epoch 27/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.9717 - vit_loss: 1.4163 - model0_loss: 1.3149 - average_loss: 1.1566 - vit_accuracy: 0.6417 - model0_accuracy: 0.6643 - average_accuracy: 0.6968 - val_loss: 2.1595 - val_vit_loss: 0.6397 - val_model0_loss: 0.4825 - val_average_loss: 0.4075 - val_vit_accuracy: 0.8387 - val_model0_accuracy: 0.8715 - val_average_accuracy: 0.8832\n",
            "Epoch 28/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.9155 - vit_loss: 1.3942 - model0_loss: 1.3067 - average_loss: 1.1456 - vit_accuracy: 0.6461 - model0_accuracy: 0.6646 - average_accuracy: 0.7011 - val_loss: 2.1808 - val_vit_loss: 0.6706 - val_model0_loss: 0.4806 - val_average_loss: 0.4108 - val_vit_accuracy: 0.8298 - val_model0_accuracy: 0.8716 - val_average_accuracy: 0.8866\n",
            "Epoch 29/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.8854 - vit_loss: 1.3919 - model0_loss: 1.2994 - average_loss: 1.1396 - vit_accuracy: 0.6457 - model0_accuracy: 0.6672 - average_accuracy: 0.7011 - val_loss: 2.1469 - val_vit_loss: 0.6353 - val_model0_loss: 0.4902 - val_average_loss: 0.4033 - val_vit_accuracy: 0.8375 - val_model0_accuracy: 0.8715 - val_average_accuracy: 0.8863\n",
            "Epoch 30/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.8604 - vit_loss: 1.3877 - model0_loss: 1.2937 - average_loss: 1.1346 - vit_accuracy: 0.6478 - model0_accuracy: 0.6709 - average_accuracy: 0.7011 - val_loss: 2.1335 - val_vit_loss: 0.6220 - val_model0_loss: 0.4791 - val_average_loss: 0.4029 - val_vit_accuracy: 0.8383 - val_model0_accuracy: 0.8698 - val_average_accuracy: 0.8865\n",
            "Epoch 31/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.9239 - vit_loss: 1.3928 - model0_loss: 1.2995 - average_loss: 1.1491 - vit_accuracy: 0.6465 - model0_accuracy: 0.6690 - average_accuracy: 0.7031 - val_loss: 2.1252 - val_vit_loss: 0.6339 - val_model0_loss: 0.4688 - val_average_loss: 0.4017 - val_vit_accuracy: 0.8405 - val_model0_accuracy: 0.8720 - val_average_accuracy: 0.8890\n",
            "Epoch 32/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.8191 - vit_loss: 1.3670 - model0_loss: 1.2825 - average_loss: 1.1278 - vit_accuracy: 0.6521 - model0_accuracy: 0.6711 - average_accuracy: 0.7057 - val_loss: 2.1346 - val_vit_loss: 0.6257 - val_model0_loss: 0.4834 - val_average_loss: 0.4021 - val_vit_accuracy: 0.8402 - val_model0_accuracy: 0.8707 - val_average_accuracy: 0.8863\n",
            "Epoch 33/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.7181 - vit_loss: 1.3547 - model0_loss: 1.2618 - average_loss: 1.1071 - vit_accuracy: 0.6525 - model0_accuracy: 0.6796 - average_accuracy: 0.7115 - val_loss: 2.0915 - val_vit_loss: 0.6150 - val_model0_loss: 0.4779 - val_average_loss: 0.3931 - val_vit_accuracy: 0.8441 - val_model0_accuracy: 0.8719 - val_average_accuracy: 0.8902\n",
            "Epoch 34/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.7920 - vit_loss: 1.3585 - model0_loss: 1.2856 - average_loss: 1.1211 - vit_accuracy: 0.6536 - model0_accuracy: 0.6730 - average_accuracy: 0.7081 - val_loss: 2.1336 - val_vit_loss: 0.6319 - val_model0_loss: 0.4825 - val_average_loss: 0.4016 - val_vit_accuracy: 0.8404 - val_model0_accuracy: 0.8739 - val_average_accuracy: 0.8902\n",
            "Epoch 35/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.7233 - vit_loss: 1.3520 - model0_loss: 1.2651 - average_loss: 1.1080 - vit_accuracy: 0.6543 - model0_accuracy: 0.6757 - average_accuracy: 0.7092 - val_loss: 2.0986 - val_vit_loss: 0.6225 - val_model0_loss: 0.4662 - val_average_loss: 0.3964 - val_vit_accuracy: 0.8449 - val_model0_accuracy: 0.8747 - val_average_accuracy: 0.8880\n",
            "Epoch 36/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.6517 - vit_loss: 1.3345 - model0_loss: 1.2495 - average_loss: 1.0942 - vit_accuracy: 0.6577 - model0_accuracy: 0.6811 - average_accuracy: 0.7122 - val_loss: 2.0785 - val_vit_loss: 0.6229 - val_model0_loss: 0.4704 - val_average_loss: 0.3906 - val_vit_accuracy: 0.8456 - val_model0_accuracy: 0.8738 - val_average_accuracy: 0.8928\n",
            "Epoch 37/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.6662 - vit_loss: 1.3395 - model0_loss: 1.2483 - average_loss: 1.0976 - vit_accuracy: 0.6595 - model0_accuracy: 0.6784 - average_accuracy: 0.7131 - val_loss: 2.0479 - val_vit_loss: 0.6164 - val_model0_loss: 0.4672 - val_average_loss: 0.3840 - val_vit_accuracy: 0.8489 - val_model0_accuracy: 0.8754 - val_average_accuracy: 0.8946\n",
            "Epoch 38/90\n",
            "782/782 [==============================] - 1155s 1s/step - loss: 5.6328 - vit_loss: 1.3210 - model0_loss: 1.2494 - average_loss: 1.0905 - vit_accuracy: 0.6620 - model0_accuracy: 0.6783 - average_accuracy: 0.7169 - val_loss: 2.0236 - val_vit_loss: 0.6072 - val_model0_loss: 0.4575 - val_average_loss: 0.3803 - val_vit_accuracy: 0.8483 - val_model0_accuracy: 0.8768 - val_average_accuracy: 0.8945\n",
            "Epoch 39/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.6073 - vit_loss: 1.3135 - model0_loss: 1.2429 - average_loss: 1.0858 - vit_accuracy: 0.6646 - model0_accuracy: 0.6814 - average_accuracy: 0.7174 - val_loss: 2.0877 - val_vit_loss: 0.6114 - val_model0_loss: 0.4826 - val_average_loss: 0.3916 - val_vit_accuracy: 0.8475 - val_model0_accuracy: 0.8721 - val_average_accuracy: 0.8947\n",
            "Epoch 40/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.5601 - vit_loss: 1.3145 - model0_loss: 1.2309 - average_loss: 1.0760 - vit_accuracy: 0.6636 - model0_accuracy: 0.6827 - average_accuracy: 0.7178 - val_loss: 2.0497 - val_vit_loss: 0.6085 - val_model0_loss: 0.4684 - val_average_loss: 0.3848 - val_vit_accuracy: 0.8513 - val_model0_accuracy: 0.8744 - val_average_accuracy: 0.8938\n",
            "Epoch 41/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.4822 - vit_loss: 1.2971 - model0_loss: 1.2167 - average_loss: 1.0604 - vit_accuracy: 0.6692 - model0_accuracy: 0.6858 - average_accuracy: 0.7208 - val_loss: 2.0282 - val_vit_loss: 0.5961 - val_model0_loss: 0.4617 - val_average_loss: 0.3816 - val_vit_accuracy: 0.8506 - val_model0_accuracy: 0.8756 - val_average_accuracy: 0.8945\n",
            "Epoch 42/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.5309 - vit_loss: 1.3112 - model0_loss: 1.2210 - average_loss: 1.0707 - vit_accuracy: 0.6678 - model0_accuracy: 0.6876 - average_accuracy: 0.7215 - val_loss: 2.0438 - val_vit_loss: 0.6047 - val_model0_loss: 0.4690 - val_average_loss: 0.3835 - val_vit_accuracy: 0.8506 - val_model0_accuracy: 0.8750 - val_average_accuracy: 0.8945\n",
            "Epoch 43/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.5539 - vit_loss: 1.3027 - model0_loss: 1.2302 - average_loss: 1.0755 - vit_accuracy: 0.6669 - model0_accuracy: 0.6845 - average_accuracy: 0.7204 - val_loss: 2.0329 - val_vit_loss: 0.6085 - val_model0_loss: 0.4566 - val_average_loss: 0.3827 - val_vit_accuracy: 0.8490 - val_model0_accuracy: 0.8796 - val_average_accuracy: 0.8946\n",
            "Epoch 44/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.4159 - vit_loss: 1.2759 - model0_loss: 1.2008 - average_loss: 1.0481 - vit_accuracy: 0.6741 - model0_accuracy: 0.6903 - average_accuracy: 0.7268 - val_loss: 2.0155 - val_vit_loss: 0.6102 - val_model0_loss: 0.4562 - val_average_loss: 0.3783 - val_vit_accuracy: 0.8479 - val_model0_accuracy: 0.8760 - val_average_accuracy: 0.8959\n",
            "Epoch 45/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.4454 - vit_loss: 1.2803 - model0_loss: 1.2050 - average_loss: 1.0545 - vit_accuracy: 0.6729 - model0_accuracy: 0.6905 - average_accuracy: 0.7259 - val_loss: 1.9793 - val_vit_loss: 0.5873 - val_model0_loss: 0.4477 - val_average_loss: 0.3724 - val_vit_accuracy: 0.8484 - val_model0_accuracy: 0.8798 - val_average_accuracy: 0.8967\n",
            "Epoch 46/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.3764 - vit_loss: 1.2681 - model0_loss: 1.1918 - average_loss: 1.0404 - vit_accuracy: 0.6763 - model0_accuracy: 0.6910 - average_accuracy: 0.7286 - val_loss: 1.9810 - val_vit_loss: 0.6031 - val_model0_loss: 0.4439 - val_average_loss: 0.3723 - val_vit_accuracy: 0.8501 - val_model0_accuracy: 0.8792 - val_average_accuracy: 0.8969\n",
            "Epoch 47/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.3562 - vit_loss: 1.2672 - model0_loss: 1.1911 - average_loss: 1.0356 - vit_accuracy: 0.6755 - model0_accuracy: 0.6934 - average_accuracy: 0.7262 - val_loss: 1.9793 - val_vit_loss: 0.6062 - val_model0_loss: 0.4423 - val_average_loss: 0.3720 - val_vit_accuracy: 0.8481 - val_model0_accuracy: 0.8806 - val_average_accuracy: 0.8950\n",
            "Epoch 48/90\n",
            "782/782 [==============================] - 1136s 1s/step - loss: 5.2926 - vit_loss: 1.2432 - model0_loss: 1.1800 - average_loss: 1.0234 - vit_accuracy: 0.6804 - model0_accuracy: 0.6944 - average_accuracy: 0.7309 - val_loss: 1.9969 - val_vit_loss: 0.6051 - val_model0_loss: 0.4482 - val_average_loss: 0.3754 - val_vit_accuracy: 0.8485 - val_model0_accuracy: 0.8828 - val_average_accuracy: 0.8980\n",
            "Epoch 49/90\n",
            "782/782 [==============================] - 1136s 1s/step - loss: 5.3068 - vit_loss: 1.2478 - model0_loss: 1.1773 - average_loss: 1.0271 - vit_accuracy: 0.6807 - model0_accuracy: 0.6956 - average_accuracy: 0.7314 - val_loss: 2.0100 - val_vit_loss: 0.6133 - val_model0_loss: 0.4520 - val_average_loss: 0.3774 - val_vit_accuracy: 0.8499 - val_model0_accuracy: 0.8809 - val_average_accuracy: 0.8956\n",
            "Epoch 50/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.2982 - vit_loss: 1.2532 - model0_loss: 1.1766 - average_loss: 1.0246 - vit_accuracy: 0.6812 - model0_accuracy: 0.6974 - average_accuracy: 0.7313 - val_loss: 1.9734 - val_vit_loss: 0.6028 - val_model0_loss: 0.4450 - val_average_loss: 0.3703 - val_vit_accuracy: 0.8517 - val_model0_accuracy: 0.8822 - val_average_accuracy: 0.8990\n",
            "Epoch 51/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.2405 - vit_loss: 1.2391 - model0_loss: 1.1635 - average_loss: 1.0136 - vit_accuracy: 0.6836 - model0_accuracy: 0.6994 - average_accuracy: 0.7355 - val_loss: 1.9952 - val_vit_loss: 0.6094 - val_model0_loss: 0.4473 - val_average_loss: 0.3748 - val_vit_accuracy: 0.8502 - val_model0_accuracy: 0.8827 - val_average_accuracy: 0.8976\n",
            "Epoch 52/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.2329 - vit_loss: 1.2318 - model0_loss: 1.1625 - average_loss: 1.0124 - vit_accuracy: 0.6839 - model0_accuracy: 0.7011 - average_accuracy: 0.7362 - val_loss: 1.9742 - val_vit_loss: 0.6059 - val_model0_loss: 0.4397 - val_average_loss: 0.3712 - val_vit_accuracy: 0.8484 - val_model0_accuracy: 0.8846 - val_average_accuracy: 0.8980\n",
            "Epoch 53/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.2294 - vit_loss: 1.2378 - model0_loss: 1.1541 - average_loss: 1.0126 - vit_accuracy: 0.6839 - model0_accuracy: 0.7015 - average_accuracy: 0.7359 - val_loss: 1.9719 - val_vit_loss: 0.5970 - val_model0_loss: 0.4407 - val_average_loss: 0.3711 - val_vit_accuracy: 0.8501 - val_model0_accuracy: 0.8820 - val_average_accuracy: 0.8973\n",
            "Epoch 54/90\n",
            "782/782 [==============================] - 1135s 1s/step - loss: 5.2181 - vit_loss: 1.2281 - model0_loss: 1.1566 - average_loss: 1.0100 - vit_accuracy: 0.6832 - model0_accuracy: 0.7028 - average_accuracy: 0.7359 - val_loss: 1.9511 - val_vit_loss: 0.5947 - val_model0_loss: 0.4368 - val_average_loss: 0.3667 - val_vit_accuracy: 0.8549 - val_model0_accuracy: 0.8844 - val_average_accuracy: 0.8994\n",
            "Epoch 55/90\n",
            "782/782 [==============================] - 1135s 1s/step - loss: 5.1995 - vit_loss: 1.2230 - model0_loss: 1.1558 - average_loss: 1.0059 - vit_accuracy: 0.6864 - model0_accuracy: 0.7034 - average_accuracy: 0.7363 - val_loss: 1.9695 - val_vit_loss: 0.6011 - val_model0_loss: 0.4408 - val_average_loss: 0.3701 - val_vit_accuracy: 0.8500 - val_model0_accuracy: 0.8848 - val_average_accuracy: 0.8989\n",
            "Epoch 56/90\n",
            "782/782 [==============================] - 1135s 1s/step - loss: 5.1473 - vit_loss: 1.2121 - model0_loss: 1.1366 - average_loss: 0.9970 - vit_accuracy: 0.6876 - model0_accuracy: 0.7059 - average_accuracy: 0.7392 - val_loss: 1.9631 - val_vit_loss: 0.5990 - val_model0_loss: 0.4409 - val_average_loss: 0.3687 - val_vit_accuracy: 0.8505 - val_model0_accuracy: 0.8856 - val_average_accuracy: 0.8976\n",
            "Epoch 57/90\n",
            "782/782 [==============================] - 1136s 1s/step - loss: 5.1475 - vit_loss: 1.2157 - model0_loss: 1.1421 - average_loss: 0.9958 - vit_accuracy: 0.6884 - model0_accuracy: 0.7064 - average_accuracy: 0.7422 - val_loss: 1.9605 - val_vit_loss: 0.5948 - val_model0_loss: 0.4426 - val_average_loss: 0.3680 - val_vit_accuracy: 0.8507 - val_model0_accuracy: 0.8850 - val_average_accuracy: 0.8990\n",
            "Epoch 58/90\n",
            "782/782 [==============================] - 1136s 1s/step - loss: 5.1459 - vit_loss: 1.2153 - model0_loss: 1.1422 - average_loss: 0.9955 - vit_accuracy: 0.6905 - model0_accuracy: 0.7043 - average_accuracy: 0.7398 - val_loss: 1.9456 - val_vit_loss: 0.5908 - val_model0_loss: 0.4390 - val_average_loss: 0.3653 - val_vit_accuracy: 0.8504 - val_model0_accuracy: 0.8853 - val_average_accuracy: 0.8988\n",
            "Epoch 59/90\n",
            "782/782 [==============================] - 1136s 1s/step - loss: 5.1308 - vit_loss: 1.2069 - model0_loss: 1.1413 - average_loss: 0.9925 - vit_accuracy: 0.6909 - model0_accuracy: 0.7055 - average_accuracy: 0.7411 - val_loss: 1.9339 - val_vit_loss: 0.5880 - val_model0_loss: 0.4346 - val_average_loss: 0.3633 - val_vit_accuracy: 0.8505 - val_model0_accuracy: 0.8865 - val_average_accuracy: 0.8991\n",
            "Epoch 60/90\n",
            "782/782 [==============================] - 1136s 1s/step - loss: 5.0690 - vit_loss: 1.1976 - model0_loss: 1.1246 - average_loss: 0.9806 - vit_accuracy: 0.6918 - model0_accuracy: 0.7074 - average_accuracy: 0.7424 - val_loss: 1.9460 - val_vit_loss: 0.5984 - val_model0_loss: 0.4369 - val_average_loss: 0.3652 - val_vit_accuracy: 0.8503 - val_model0_accuracy: 0.8867 - val_average_accuracy: 0.8990\n",
            "Epoch 61/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.0594 - vit_loss: 1.1891 - model0_loss: 1.1220 - average_loss: 0.9793 - vit_accuracy: 0.6936 - model0_accuracy: 0.7087 - average_accuracy: 0.7440 - val_loss: 1.9289 - val_vit_loss: 0.5911 - val_model0_loss: 0.4326 - val_average_loss: 0.3622 - val_vit_accuracy: 0.8524 - val_model0_accuracy: 0.8867 - val_average_accuracy: 0.9006\n",
            "Epoch 62/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.0575 - vit_loss: 1.1902 - model0_loss: 1.1213 - average_loss: 0.9789 - vit_accuracy: 0.6924 - model0_accuracy: 0.7106 - average_accuracy: 0.7425 - val_loss: 1.9351 - val_vit_loss: 0.5930 - val_model0_loss: 0.4338 - val_average_loss: 0.3634 - val_vit_accuracy: 0.8537 - val_model0_accuracy: 0.8879 - val_average_accuracy: 0.8987\n",
            "Epoch 63/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.1173 - vit_loss: 1.1991 - model0_loss: 1.1370 - average_loss: 0.9904 - vit_accuracy: 0.6934 - model0_accuracy: 0.7067 - average_accuracy: 0.7435 - val_loss: 1.9400 - val_vit_loss: 0.5920 - val_model0_loss: 0.4342 - val_average_loss: 0.3646 - val_vit_accuracy: 0.8522 - val_model0_accuracy: 0.8869 - val_average_accuracy: 0.8993\n",
            "Epoch 64/90\n",
            "782/782 [==============================] - 1137s 1s/step - loss: 5.0531 - vit_loss: 1.1823 - model0_loss: 1.1243 - average_loss: 0.9779 - vit_accuracy: 0.6934 - model0_accuracy: 0.7087 - average_accuracy: 0.7427 - val_loss: 1.9329 - val_vit_loss: 0.5884 - val_model0_loss: 0.4338 - val_average_loss: 0.3632 - val_vit_accuracy: 0.8523 - val_model0_accuracy: 0.8873 - val_average_accuracy: 0.8994\n",
            "Epoch 65/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 4.9959 - vit_loss: 1.1746 - model0_loss: 1.1118 - average_loss: 0.9663 - vit_accuracy: 0.6975 - model0_accuracy: 0.7127 - average_accuracy: 0.7465 - val_loss: 1.9302 - val_vit_loss: 0.5929 - val_model0_loss: 0.4326 - val_average_loss: 0.3624 - val_vit_accuracy: 0.8523 - val_model0_accuracy: 0.8895 - val_average_accuracy: 0.9016\n",
            "Epoch 66/90\n",
            "782/782 [==============================] - 1138s 1s/step - loss: 5.0459 - vit_loss: 1.1823 - model0_loss: 1.1200 - average_loss: 0.9768 - vit_accuracy: 0.6955 - model0_accuracy: 0.7087 - average_accuracy: 0.7451 - val_loss: 1.9346 - val_vit_loss: 0.5926 - val_model0_loss: 0.4341 - val_average_loss: 0.3632 - val_vit_accuracy: 0.8520 - val_model0_accuracy: 0.8886 - val_average_accuracy: 0.9007\n",
            "Epoch 67/90\n",
            "380/782 [=============>................] - ETA: 8:10 - loss: 5.0311 - vit_loss: 1.1884 - model0_loss: 1.1132 - average_loss: 0.9738 - vit_accuracy: 0.6926 - model0_accuracy: 0.7138 - average_accuracy: 0.7468"
          ]
        }
      ],
      "source": [
        "optimizer = keras.optimizers.Adamax(scheduled_lrs, clipnorm=1.0)\n",
        "lossWeights = {'model0':0.7,'vit':0.3,'average':4.0}\n",
        "loss5 = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "model_final.compile( optimizer=optimizer1, metrics=[\"accuracy\"],loss={'model0':loss5,'vit':loss5,'average':loss5},loss_weights=lossWeights)\n",
        "\n",
        "history = model_final.fit(train_dataset, validation_data=val_dataset, epochs=90,callbacks=[mycallback])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Em_vCIvsWgol",
        "ra0K4ju7uU-P",
        "9iJKlP4OUxTP",
        "wMKcSVz1tItl",
        "8pQrnYlUtIto",
        "z9KveLojtItq",
        "gaR5YSPftItw",
        "LIqpvjSCiHhn",
        "B79pvsRbirs0",
        "c5S6rz0Aogt1",
        "DJy1pvBqovBA",
        "p-JmQby_jm2a",
        "nyNvEJ_dL0v2"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "environment": {
      "name": "tf2-gpu.2-4.m61",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}