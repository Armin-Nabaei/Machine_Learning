{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image classification with Vision Transformer\n",
        "This example implements for image classification,and demonstrates it on the CIFAR-10 and CIFAR-100 datasetS.\n",
        "The HYBRID MODEL consists of a modified ViT and attentive modules.\n",
        "\n",
        "**!pip install -U tensorflow-addons**\n"
      ],
      "metadata": {
        "id": "Z0dW15yxwZ9F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em_vCIvsWgol"
      },
      "source": [
        "# LIBRARIES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QGAEnuJ8WHd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10,cifar100\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import time\n",
        "from keras.applications.nasnet import NASNetMobile, preprocess_input\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from __future__ import print_function, division, absolute_import\n",
        "import timeit\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalMaxPooling2D,AveragePooling2D,UpSampling2D,Conv2DTranspose,DepthwiseConv2D,Conv1D,Add\n",
        "from tensorflow.keras.layers import ELU,SeparableConv2D,DepthwiseConv1D\n",
        "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense,ZeroPadding2D,Concatenate,AveragePooling1D\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD, Adam,Adadelta,Adamax\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau,LearningRateScheduler\n",
        "from keras.models import load_model\n",
        "import os\n",
        "from PIL import Image\n",
        "import requests\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.activations import *\n",
        "from tensorflow.python.keras.utils.generic_utils import deserialize_keras_object\n",
        "from tensorflow.python.keras.utils.generic_utils import serialize_keras_object\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import nn\n",
        "from numpy.core.fromnumeric import transpose\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load data"
      ],
      "metadata": {
        "id": "ra0K4ju7uU-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "train_lab_categorical = tf.keras.utils.to_categorical(y_train, num_classes=10, dtype='uint8')\n",
        "test_lab_categorical = tf.keras.utils.to_categorical(y_test, num_classes=10, dtype='uint8')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_im, valid_im, train_lab, valid_lab = train_test_split(x_train, train_lab_categorical, test_size=0.20,\n",
        "                                                            stratify=train_lab_categorical,\n",
        "                                                            random_state=40, shuffle = True)\n",
        "\n",
        "training_data = tf.data.Dataset.from_tensor_slices((train_im, train_lab))\n",
        "validation_data = tf.data.Dataset.from_tensor_slices((valid_im, valid_lab))\n",
        "#test_data = tf.data.Dataset.from_tensor_slices((x_test, test_lab_categorical))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_data = training_data.shuffle(buffer_size=50000).batch(64).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "valid_data = validation_data.shuffle(buffer_size=10000).batch(64).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "#test_data = test_data.shuffle(buffer_size=10000).batch(32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "mqw46M--uUPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525f4f67-e4f5-40d1-dfee-28827e318ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 11s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rescale_layer_cnn = tf.keras.layers.Rescaling(1./127.5,offset=-1)\n",
        "rescale_layer_vit = tf.keras.layers.Rescaling(1./127.5,offset=-1)\n",
        "\n",
        "rescale_resize_vit = tf.keras.layers.experimental.preprocessing.Resizing(224,224, interpolation=\"lanczos5\")\n",
        "rescale_resize_cnn = tf.keras.layers.experimental.preprocessing.Resizing(224,224, interpolation=\"lanczos5\")\n",
        "\n",
        "data_augmentation_cnn = tf.keras.Sequential([\n",
        "  #layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "  #layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "  #layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3)),\n",
        "  #layers.experimental.preprocessing.RandomTranslation(0.0, 0.0, fill_mode='reflect', interpolation='bilinear',)\n",
        "])\n",
        "\n",
        "data_augmentation_vit = tf.keras.Sequential([\n",
        "  #layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "  #layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "  #layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3)),\n",
        "  #layers.experimental.preprocessing.RandomTranslation(0.0, 0.0, fill_mode='reflect', interpolation='bilinear',)\n",
        "])"
      ],
      "metadata": {
        "id": "b4szHazjHsm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Labe Encoding"
      ],
      "metadata": {
        "id": "9p71BI9kITx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = tf.cast(y_train,tf.int32)\n",
        "y_test = tf.cast(y_test,tf.int32)\n",
        "y_train = tf.one_hot(y_train,depth=10)\n",
        "y_test = tf.one_hot(y_test, depth=10)\n",
        "y_train = tf.cast(y_train,tf.float32)\n",
        "y_test = tf.cast(y_test,tf.float32)"
      ],
      "metadata": {
        "id": "FSzTfs7SKcPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lr warm up"
      ],
      "metadata": {
        "id": "9iJKlP4OUxTP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmLvpwaCIkUr"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "\n",
        "import random\n",
        "class WarmUpCosine(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(\n",
        "        self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps\n",
        "    ):\n",
        "        super(WarmUpCosine, self).__init__()\n",
        "\n",
        "        self.learning_rate_base = learning_rate_base\n",
        "        self.total_steps = total_steps\n",
        "        self.warmup_learning_rate = warmup_learning_rate\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.pi = tf.constant(np.pi)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        if self.total_steps < self.warmup_steps:\n",
        "            raise ValueError(\"Total_steps must be larger or equal to warmup_steps.\")\n",
        "        learning_rate = (\n",
        "            0.5\n",
        "            * self.learning_rate_base\n",
        "            * (\n",
        "                1\n",
        "                + tf.cos(\n",
        "                    self.pi\n",
        "                    * (tf.cast(step, tf.float32) - self.warmup_steps)\n",
        "                    / float(self.total_steps - self.warmup_steps)\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "\n",
        "        if self.warmup_steps > 0:\n",
        "            if self.learning_rate_base < self.warmup_learning_rate:\n",
        "                raise ValueError(\n",
        "                    \"Learning_rate_base must be larger or equal to \"\n",
        "                    \"warmup_learning_rate.\"\n",
        "                )\n",
        "            slope = (\n",
        "                self.learning_rate_base - self.warmup_learning_rate\n",
        "            ) / self.warmup_steps\n",
        "            warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n",
        "            learning_rate = tf.where(\n",
        "                step < self.warmup_steps, warmup_rate, learning_rate\n",
        "            )\n",
        "        return tf.where(\n",
        "            step > self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n",
        "        )\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "                'learning_rate_base': self.learning_rate_base,\n",
        "                'total_steps': self.total_steps,\n",
        "                'warmup_learning_rate': self.warmup_learning_rate,\n",
        "                'warmup_steps': self.warmup_steps,\n",
        "\n",
        "                 }\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pet4gNehIuAV",
        "outputId": "9f64ce72-07ab-438d-cf2f-ad0c7e3b7fe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39062\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "TOTAL_STEPS = int((50000 / BATCH_SIZE) * EPOCHS)\n",
        "WARMUP_STEPS = 10\n",
        "INIT_LR = 0.03\n",
        "WAMRUP_LR = 0.006\n",
        "\n",
        "print(TOTAL_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "IvPpu6HeI0Mp",
        "outputId": "4740062d-4c1c-4306-8dcb-d4fa65a0794e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "scheduled_lrs = WarmUpCosine(\n",
        "    learning_rate_base=INIT_LR,\n",
        "    total_steps=TOTAL_STEPS,\n",
        "    warmup_learning_rate=WAMRUP_LR,\n",
        "    warmup_steps=WARMUP_STEPS,\n",
        ")\n",
        "\n",
        "lrs = [scheduled_lrs(step) for step in range(TOTAL_STEPS)]\n",
        "plt.plot(lrs)\n",
        "plt.xlabel(\"Step\", fontsize=14)\n",
        "plt.ylabel(\"LR\", fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMKcSVz1tItl"
      },
      "source": [
        "# hyperparameter setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBMBuc_D9yyt"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "num_classes=10\n",
        "batch_size = 64\n",
        "num_epochs = 100\n",
        "image_size = 224  # We'll resize input images to this size\n",
        "patch_size = 64 # Size of the patches to be extract from the input images\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "]  # Size of the transformer layers\n",
        "transformer_layers =2\n",
        "mlp_head_units = [2048,1024]  # Size of the dense layers of the final classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pQrnYlUtIto"
      },
      "source": [
        "## data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4Ob6X6ptItp"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "        #layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        #layers.RandomFlip(\"horizontal\"),\n",
        "        #layers.RandomRotation(factor=0.02),\n",
        "        #layers.RandomZoom(\n",
        "         #   height_factor=0.2, width_factor=0.2\n",
        "        #),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9KveLojtItq"
      },
      "source": [
        "## Implement multilayer perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVShQ_4XtItq"
      },
      "outputs": [],
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcOq3beitItv"
      },
      "source": [
        "## patch encoding layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAFgXj74VOvl"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"SAME\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches\n",
        "##############\n",
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        ) #produce a table to map inputs to embedding vectors\n",
        "\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaR5YSPftItw"
      },
      "source": [
        "# Bottlneck_Channelmix Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3cvCNX_PQwX"
      },
      "outputs": [],
      "source": [
        "def channel_mix(l,imgs):\n",
        "\n",
        "    channel_r=imgs[:,:,0:1]\n",
        "    channel_g=imgs[:,:,1:2]\n",
        "    channel_b=imgs[:,:,2:3]\n",
        "\n",
        "    channel1_r=l[:,:,0:21]\n",
        "    channel1_g=l[:,:,21:41]\n",
        "    channel1_b=l[:,:,43:63]\n",
        "\n",
        "    l1 = tf.concat([channel1_r, channel_r],axis=2)\n",
        "    l2 = tf.concat([channel1_g, channel_g],axis=2)\n",
        "    l3 = tf.concat([channel1_b, channel_b],axis=2)\n",
        "\n",
        "    l = tf.concat([l1,l2,l3],axis=2)\n",
        "\n",
        "    return l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inb_AvviE3YS"
      },
      "outputs": [],
      "source": [
        "\n",
        "def bottleneck(input,layers):\n",
        "    for _ in range(layers):\n",
        "        print(\"INPUT SHAPE\",input.shape)\n",
        "        x=Conv1D(64, 5, padding = \"same\", kernel_initializer=\"he_normal\")(input)\n",
        "        x=Activation('elu')(x)\n",
        "        print(\"First CONV SHAPE \",x.shape)\n",
        "        x2= DepthwiseConv1D( 1, padding = 'same', kernel_initializer=\"he_normal\",depth_multiplier=2)(input)\n",
        "        print(\"input increased dimension Shape\",x2.shape)\n",
        "        x = Add()([input,x])\n",
        "        x=Conv1D(64, 1, padding = \"same\", groups=4 , kernel_initializer=\"he_normal\")(x)\n",
        "        x=Activation('elu')(x)\n",
        "        print(\"Decreased dimension shape\",x.shape)\n",
        "        x= channel_mix (x, input)\n",
        "        print(\"OUTPUT x SHAPE\",x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEz4wIBMPNcP"
      },
      "outputs": [],
      "source": [
        "#@under_name_scope()\n",
        "def channel_shuffle(l, group):\n",
        "    in_shape = l.get_shape().as_list()\n",
        "    in_channel = in_shape[2]\n",
        "    assert in_channel % group == 0, in_channel\n",
        "    l = tf.reshape(l, [-1, in_channel // group, group] + in_shape[-1:])\n",
        "    l = tf.transpose(l, [0, 2, 1, 3])\n",
        "    l = tf.reshape(l, [-1, in_channel] + in_shape[-1:])\n",
        "    print('shuffle output',l.shape)\n",
        "    return l\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTSK0diR1VBv"
      },
      "outputs": [],
      "source": [
        "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "inception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
        "handle=\"https://tfhub.dev/sayakpaul/vit_s16_fe/1\"\n",
        "b1_vit=\"https://tfhub.dev/sayakpaul/vit_b8_classification/1\"\n",
        "mixer_1 = \"https://tfhub.dev/sayakpaul/mixer_b16_sam_classification/1\"\n",
        "feature_extractor_model = mixer_1\n",
        "mixer_2 = \"https://tfhub.dev/sayakpaul/mixer_b16_sam_fe/1\"\n",
        "feature_extractor_model2 = mixer_2\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modified Vit"
      ],
      "metadata": {
        "id": "LIqpvjSCiHhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_primary = layers.Input(shape=(32,32, 3))\n",
        "\n",
        "inputs_vit_rescaled=rescale_layer_vit (inputs_primary)\n",
        "inputs_vit_resized = rescale_resize_vit (inputs_vit_rescaled)\n",
        "print (inputs_vit_resized.shape)\n",
        "input_augmented_vit = data_augmentation_vit (inputs_vit_resized)\n",
        "\n",
        "#################################\n",
        "\n",
        "mixer_3 = \"https://tfhub.dev/sayakpaul/vit_b8_classification/1\"\n",
        "feature_extractor_model2 = mixer_3\n",
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_model2,input_shape=(224,224 ,3),trainable=False)\n",
        "augmented1 = feature_extractor_layer(input_augmented_vit)\n",
        "print('feature_extractor output:',augmented1.shape)\n",
        "augmented12 = tf.expand_dims(augmented1, axis=1)\n",
        "print('12:',augmented12.shape)\n",
        "augmented13 = tf.expand_dims(augmented12, axis=2)\n",
        "print('13:',augmented13.shape)\n",
        "#######################################################\n",
        "# Create patches.\n",
        "patches = Patches(patch_size)(augmented13)\n",
        "# Encode patches.\n",
        "print(' patches:',patches.shape)\n",
        "encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
        "print(' encoded_patches output :',encoded_patches.shape)\n",
        "\n",
        "for _ in range(transformer_layers):\n",
        "    attention_output = layers.MultiHeadAttention(\n",
        "        num_heads=num_heads, key_dim=projection_dim, dropout=0.0\n",
        "    )(encoded_patches, encoded_patches)\n",
        "\n",
        "    # Bottlneck for odd layers\n",
        "    if _  <= (1):\n",
        "       attention_output = bottleneck(attention_output,1)\n",
        "\n",
        "    # Skip connection 1.\n",
        "    x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "    # MLP.\n",
        "    x3 = mlp(x2, hidden_units=transformer_units, dropout_rate=0.0)\n",
        "\n",
        "    # Skip connection 2.\n",
        "    encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    ##################\n",
        "representation2 = layers.Flatten()(encoded_patches)\n",
        "representation = layers.Dropout(0.2)(representation2)\n",
        "# Add MLP.\n",
        "features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.0)\n",
        "model_vit = Model(inputs=inputs_primary, outputs=features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdDiVccYiQ67",
        "outputId": "e60e015c-cbdf-41b9-b2f8-1b13110bfe93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 3)\n",
            "feature_extractor output: (None, 1000)\n",
            "12: (None, 1, 1000)\n",
            "13: (None, 1, 1, 1000)\n",
            " patches: (None, None, 4096000)\n",
            " encoded_patches output : (None, 9, 64)\n",
            "INPUT SHAPE (None, 9, 64)\n",
            "First CONV SHAPE  (None, 9, 64)\n",
            "input increased dimension Shape (None, 9, 128)\n",
            "Decreased dimension shape (None, 9, 64)\n",
            "OUTPUT x SHAPE (None, 9, 64)\n",
            "INPUT SHAPE (None, 9, 64)\n",
            "First CONV SHAPE  (None, 9, 64)\n",
            "input increased dimension Shape (None, 9, 128)\n",
            "Decreased dimension shape (None, 9, 64)\n",
            "OUTPUT x SHAPE (None, 9, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Module 1"
      ],
      "metadata": {
        "id": "B79pvsRbirs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL 0\n",
        "inputs_primary = layers.Input(shape=(32,32, 3))\n",
        "##########\n",
        "inputs_cnn_rescaled=rescale_layer_cnn (inputs_primary)\n",
        "inputs_cnn_resized = rescale_resize_cnn (inputs_cnn_rescaled)\n",
        "print (inputs_cnn_resized.shape)\n",
        "input_augmented_cnn = data_augmentation_cnn (inputs_cnn_resized)\n",
        "###################################################################\n",
        "mixer_32 = \"https://tfhub.dev/sayakpaul/vit_b8_classification/1\"\n",
        "feature_extractor_model3 = mixer_32\n",
        "feature_extractor_layer2 = hub.KerasLayer(feature_extractor_model3,input_shape=(224,224 ,3),trainable=False)\n",
        "augmented123 = feature_extractor_layer2(input_augmented_cnn)\n",
        "print('feature_extractor out:',augmented123.shape)\n",
        "#############\n",
        "augmented123=tf.expand_dims(augmented123,axis=2)\n",
        "ave1 = AveragePooling1D(pool_size=(2), padding='valid', strides=2, name='Avg_pool_1')(augmented123)\n",
        "print('pool first',ave1.shape)\n",
        "ave2 = AveragePooling1D(pool_size=(3), padding='valid', strides=3, name='Avg_pool_2')(augmented123)\n",
        "print('pool second',ave2.shape)\n",
        "ave3 = AveragePooling1D(pool_size=(5), padding='valid', strides=5, name='Avg_pool_3')(augmented123)\n",
        "print('pool third',ave3.shape)\n",
        "ave_concate = Concatenate(axis=1) ([ave1,ave2,ave3])\n",
        "print('ave_pool concate',ave_concate.shape)\n",
        "max1 = AveragePooling1D(pool_size=(2), padding='valid', strides=2, name='max_pool_1')(augmented123)\n",
        "print('max first',max1.shape)\n",
        "max2 = AveragePooling1D(pool_size=(3), padding='valid', strides=3, name='max_pool_2')(augmented123)\n",
        "print('max second',max2.shape)\n",
        "max3 = AveragePooling1D(pool_size=(5), padding='valid', strides=5, name='max_pool_3')(augmented123)\n",
        "print('max third',max3.shape)\n",
        "max_concate = Concatenate(axis=1) ([max1,max2,max3])\n",
        "print('max_pool concate',ave_concate.shape)\n",
        "pool_con= Concatenate(axis=1) ([max_concate,ave_concate])\n",
        "print('pool concate',pool_con.shape)\n",
        "pool_flattend = Flatten()(pool_con)\n",
        "print('pool flattend',pool_flattend.shape)\n",
        "#####################################################################\n",
        "s0, s1 = tf.split(pool_flattend, num_or_size_splits=2, axis=1)\n",
        "print('split shape:',s0.shape)\n",
        "a1=  tf.stack([s0, s1], axis=1)\n",
        "print('concate shape:',a1.shape)\n",
        "####################################\n",
        "input_dec=Conv1D(500, (1), padding = \"same\", kernel_initializer=\"he_normal\",name='decrease_dimension_1')(a1)\n",
        "x1_branch=Conv1D(500, (3), padding = \"same\", kernel_initializer=\"he_normal\",name='conv2D_1_module_1')(a1)\n",
        "x1_branch=BatchNormalization()(x1_branch)\n",
        "x1_branch_out = Activation(\"softmax\", dtype=tf.float32, name=\"softmax_module_1\")(x1_branch)\n",
        "x1_out = tf.math.multiply(input_dec, x1_branch_out)\n",
        "####################################\n",
        "x2_branch=Conv1D(250, (1), padding = \"same\", kernel_initializer=\"he_normal\",name='conv2D_2_module_1')(x1_out)\n",
        "print(x2_branch.shape)\n",
        "x2_branch=BatchNormalization()(x2_branch)\n",
        "x2_branch=Activation('elu')(x2_branch)\n",
        "x2_branch=DepthwiseConv1D(250, (1),padding='same', depth_multiplier=2, kernel_initializer=\"he_normal\",name='conv2D_3_module_1')(x2_branch)\n",
        "print(x2_branch.shape)\n",
        "##########################\n",
        "x2_out = x2_branch\n",
        "z= tf.math.multiply(input_dec, x2_out)\n",
        "model_1 = Model(inputs_primary, outputs=z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33LwsmImiuHZ",
        "outputId": "35ce54f3-b6a3-4beb-d909-74e29c4954d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 3)\n",
            "feature_extractor out: (None, 1000)\n",
            "pool first (None, 500, 1)\n",
            "pool second (None, 333, 1)\n",
            "pool third (None, 200, 1)\n",
            "ave_pool concate (None, 1033, 1)\n",
            "max first (None, 500, 1)\n",
            "max second (None, 333, 1)\n",
            "max third (None, 200, 1)\n",
            "max_pool concate (None, 1033, 1)\n",
            "pool concate (None, 2066, 1)\n",
            "pool flattend (None, 2066)\n",
            "split shape: (None, 1033)\n",
            "concate shape: (None, 2, 1033)\n",
            "(None, 2, 250)\n",
            "(None, 2, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Module 2"
      ],
      "metadata": {
        "id": "c5S6rz0Aogt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_primary = layers.Input(shape=(32,32, 3))\n",
        "##########\n",
        "inputs_cnn_rescaled=rescale_layer_cnn (inputs_primary)\n",
        "inputs_cnn_resized = rescale_resize_cnn (inputs_cnn_rescaled)\n",
        "print (inputs_cnn_resized.shape)\n",
        "mixer_35 = \"https://tfhub.dev/sayakpaul/vit_b8_classification/1\"\n",
        "feature_extractor_model5 = mixer_35\n",
        "feature_extractor_layer4 = hub.KerasLayer(feature_extractor_model5,input_shape=(224,224 ,3),trainable=False)\n",
        "x_resi2 = feature_extractor_layer4(inputs_cnn_resized)\n",
        "x_resi2=tf.dtypes.cast(x_resi2,tf.float32)\n",
        "model_helper_1 = Model(inputs=inputs_primary, outputs=x_resi2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvJNdNTvojZk",
        "outputId": "9a9690bf-f315-4111-f22d-c3e8f7eeb5dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Module 3"
      ],
      "metadata": {
        "id": "DJy1pvBqovBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_primary = layers.Input(shape=(32,32, 3))\n",
        "\n",
        "inputs_vit_rescaled=rescale_layer_vit (inputs_primary)\n",
        "inputs_vit_resized = rescale_resize_vit (inputs_vit_rescaled)\n",
        "print (inputs_vit_resized.shape)\n",
        "mixer_34 = \"https://tfhub.dev/sayakpaul/vit_b8_classification/1\"\n",
        "feature_extractor_model4 = mixer_34\n",
        "feature_extractor_layer3 = hub.KerasLayer(feature_extractor_model4,input_shape=(224,224 ,3),trainable=False)\n",
        "x_resi2 = feature_extractor_layer3(inputs_vit_resized)\n",
        "x_resi2=tf.dtypes.cast(x_resi2,tf.float32)\n",
        "model_helper_2 = Model(inputs=inputs_primary, outputs=x_resi2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UX5CEASio0dp",
        "outputId": "5a4473bf-c9ad-47de-81a7-a21cbdc304f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Model"
      ],
      "metadata": {
        "id": "p-JmQby_jm2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [model_1,model_vit,model_helper_1,model_helper_2]\n",
        "\n",
        "inputs_primary = layers.Input(shape=(32,32, 3))\n",
        "model_1 = [model(inputs_primary) for model in models[0:1]]\n",
        "model_vit = [model(inputs_primary) for model in models[1:2]]\n",
        "model_helper_1 = [model(inputs_primary) for model in models[2:3]]\n",
        "model_helper_2 = [model(inputs_primary) for model in models[3:4]]\n",
        "\n",
        "x3c = tf.squeeze(model_helper_1, axis=[0])\n",
        "x3c=tf.dtypes.cast(x3c,tf.float32)\n",
        "x3c = Flatten()(x3c)\n",
        "model_helper_1_out=tf.dtypes.cast(x3c,tf.float32)\n",
        "x3 = tf.squeeze(model_1, axis=[0])\n",
        "x3=tf.dtypes.cast(x3,tf.float32)\n",
        "x3 = Flatten()(x3)\n",
        "model_cnn_out=tf.dtypes.cast(x3,tf.float32)\n",
        "model_cnn_out_concatenate = Concatenate(axis=-1) ([model_cnn_out,model_helper_1_out])\n",
        "x2qx = Dense(64, activation='elu',name='dense2w')(model_cnn_out_concatenate)\n",
        "x3qx =BatchNormalization()(x2qx)\n",
        "x4qx = Dropout(0.2)(x3qx)\n",
        "x_1qx = Dense(32, activation='elu',name='dense1w')(x4qx)\n",
        "x_qx =BatchNormalization()(x_1qx)\n",
        "xq = Dropout(0.2)(x_qx)\n",
        "x_out = Dense(num_classes, dtype=tf.float32)(xq)\n",
        "x72wx = Activation(\"softmax\",name='model0')(x_out)\n",
        "##################################################################\n",
        "x3a = tf.squeeze(model_1, axis=[0])\n",
        "x3a=tf.dtypes.cast(x3a,tf.float32)\n",
        "x3a = Flatten()(x3a)\n",
        "model_cnn_outa=tf.dtypes.cast(x3a,tf.float32)\n",
        "model_cnn_out_concatenatea = Concatenate(axis=-1) ([model_cnn_out,model_helper_1_out])\n",
        "model_cnn_out_concatenatea = Flatten() (model_cnn_out_concatenatea)\n",
        "x2qxa = Dense(128, activation='elu',name='dense2w')(model_cnn_out_concatenatea)\n",
        "x3qxa =BatchNormalization()(x2qx)\n",
        "x4qxa = Dropout(0.2)(x3qx)\n",
        "x7_1qxa = Dense(64, activation='elu',name='dense1w')(x4qxa)\n",
        "x7_2qxa =BatchNormalization()(x7_1qxa)\n",
        "x7qxa = Dropout(0.2)(x7_2qxa)\n",
        "x71wxa = Dense(num_classes, dtype=tf.float32)(x7qxa)\n",
        "x72wxa = Activation(\"softmax\",name='model2')(x71wxa)\n",
        "######Model helper 2\n",
        "x3v = tf.squeeze(model_helper_2, axis=[0])\n",
        "x3v=tf.dtypes.cast(x3v,tf.float32)\n",
        "x3v = Flatten()(x3v)\n",
        "model_helper_2_out=tf.dtypes.cast(x3v,tf.float32)\n",
        "#################################\n",
        "x3v = tf.squeeze(model_vit, axis=[0])\n",
        "x3v=tf.dtypes.cast(x3v,tf.float32)\n",
        "x3v = Flatten()(x3v)\n",
        "model_vit_out=tf.dtypes.cast(x3,tf.float32)\n",
        "model_vit_out_concatenate = Concatenate(axis=-1) ([model_vit_out,model_helper_2_out])\n",
        "model_vit_out_concatenate = Flatten()(model_vit_out_concatenate)\n",
        "x2 = Dense(64, activation='elu',name='dense_vit11')(model_vit_out_concatenate)\n",
        "x3 =BatchNormalization()(x2)\n",
        "x4v = Dropout(0.2)(x3)\n",
        "x2v = Dense(32, activation='elu',name='dense_vit12')(x4v)\n",
        "x3v =BatchNormalization()(x2v)\n",
        "x4v = Dropout(0.2)(x3v)\n",
        "x_v81 = layers.Dense(num_classes)(x4v)\n",
        "x_v8 = Activation(\"softmax\",name='vit')(x_v81)\n",
        "#########################################\n",
        "avr= tf.keras.layers.Average(name='average')([x_v8,x72wx])\n",
        "model_final = Model(inputs=inputs_primary, outputs=[x_v8,x72wx,avr])"
      ],
      "metadata": {
        "id": "Ai9gyek1jpWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyNvEJ_dL0v2"
      },
      "source": [
        "# Callback function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZukQsdxEXlb",
        "outputId": "3441116b-e47b-4ce8-e8fe-faec8fdb0dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: tensorflow_hub/ENSEMBLE Vit_Cnn_CIFAR10_Exp Apr20/20231209-000433\n"
          ]
        }
      ],
      "source": [
        "# Create tensorboard callback\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "#############################\n",
        "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                                  patience=3)\n",
        "# Creating learning rate reduction callback\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
        "                                                 patience=2,\n",
        "                                                 verbose=1, #\n",
        "                                                 min_lr=1e-7)\n",
        "\n",
        "def decay(epochs, steps=100):\n",
        "    initial_lrate = 0.0001\n",
        "    drop = 0.96\n",
        "    epochs_drop = 8\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+(2*epochs)/epochs_drop)))\n",
        "    return lrate\n",
        "################################\n",
        "save_dir = os.path.join(os.getcwd(), \"/save_model\")\n",
        "filepath = \"vit_cnn_20apr.{epoch:02d}-{val_model0_accuracy:.4f}.tf\"\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(save_dir, filepath),\n",
        "                             monitor=\"val_model0_accuracy\",\n",
        "                             save_best_only=True,\n",
        "                             mode=\"max\",\n",
        "                             verbose=0)\n",
        "##############################\n",
        "lr_sc = LearningRateScheduler(decay,verbose=1)\n",
        "mycallback = [early_stopping,lr_sc,reduce_lr,\n",
        "              create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "              experiment_name=\"ENSEMBLE Vit_Cnn_CIFAR10_Exp Apr20\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN"
      ],
      "metadata": {
        "id": "_gTra8G3u9JE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Donload weights from  [link text](https://drive.google.com/drive/folders/15sN8wzAYOH6XFQiAGzA2Zg13Ykb4QZad?usp=sharing)"
      ],
      "metadata": {
        "id": "0vO8nyEW7KFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_final.load_weights(\"/content/drive/MyDrive/CIFAR10/save_models/cifar10_hybrid_vit&cnn_model_weights_98.55%.tf\")"
      ],
      "metadata": {
        "id": "JUk4DxWV6E4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile & Train"
      ],
      "metadata": {
        "id": "yz8o51lx7ViI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxbbZVFPgxH4",
        "outputId": "cf8f2c1d-eee4-4ca5-bbc0-b19719913d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 9.6e-05.\n",
            "Epoch 1/50\n",
            "625/625 [==============================] - 797s 1s/step - loss: 0.1241 - vit_loss: 0.0460 - model0_loss: 0.0447 - average_loss: 0.0395 - vit_accuracy: 0.9870 - model0_accuracy: 0.9888 - average_accuracy: 0.9893 - val_loss: 0.1626 - val_vit_loss: 0.0532 - val_model0_loss: 0.0581 - val_average_loss: 0.0528 - val_vit_accuracy: 0.9838 - val_model0_accuracy: 0.9836 - val_average_accuracy: 0.9834 - lr: 9.6000e-05\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 9.6e-05.\n",
            "Epoch 2/50\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.1146 - vit_loss: 0.0422 - model0_loss: 0.0414 - average_loss: 0.0365 - vit_accuracy: 0.9883 - model0_accuracy: 0.9888 - average_accuracy: 0.9904 - val_loss: 0.1647 - val_vit_loss: 0.0543 - val_model0_loss: 0.0580 - val_average_loss: 0.0538 - val_vit_accuracy: 0.9838 - val_model0_accuracy: 0.9832 - val_average_accuracy: 0.9839 - lr: 9.6000e-05\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 9.6e-05.\n",
            "Epoch 3/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1134 - vit_loss: 0.0423 - model0_loss: 0.0404 - average_loss: 0.0363 - vit_accuracy: 0.9882 - model0_accuracy: 0.9894 - average_accuracy: 0.9901\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.8000001697801054e-05.\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.1134 - vit_loss: 0.0423 - model0_loss: 0.0404 - average_loss: 0.0363 - vit_accuracy: 0.9882 - model0_accuracy: 0.9894 - average_accuracy: 0.9901 - val_loss: 0.1625 - val_vit_loss: 0.0532 - val_model0_loss: 0.0575 - val_average_loss: 0.0530 - val_vit_accuracy: 0.9843 - val_model0_accuracy: 0.9833 - val_average_accuracy: 0.9843 - lr: 9.6000e-05\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 9.6e-05.\n",
            "Epoch 4/50\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.1098 - vit_loss: 0.0414 - model0_loss: 0.0387 - average_loss: 0.0352 - vit_accuracy: 0.9877 - model0_accuracy: 0.9897 - average_accuracy: 0.9906 - val_loss: 0.1626 - val_vit_loss: 0.0535 - val_model0_loss: 0.0575 - val_average_loss: 0.0531 - val_vit_accuracy: 0.9844 - val_model0_accuracy: 0.9841 - val_average_accuracy: 0.9840 - lr: 9.6000e-05\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 9.216e-05.\n",
            "Epoch 5/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1086 - vit_loss: 0.0405 - model0_loss: 0.0383 - average_loss: 0.0349 - vit_accuracy: 0.9887 - model0_accuracy: 0.9900 - average_accuracy: 0.9907\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.608000017469749e-05.\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.1086 - vit_loss: 0.0405 - model0_loss: 0.0383 - average_loss: 0.0349 - vit_accuracy: 0.9887 - model0_accuracy: 0.9900 - average_accuracy: 0.9907 - val_loss: 0.1628 - val_vit_loss: 0.0536 - val_model0_loss: 0.0574 - val_average_loss: 0.0532 - val_vit_accuracy: 0.9841 - val_model0_accuracy: 0.9842 - val_average_accuracy: 0.9842 - lr: 9.2160e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 9.216e-05.\n",
            "Epoch 6/50\n",
            "625/625 [==============================] - 784s 1s/step - loss: 0.1033 - vit_loss: 0.0388 - model0_loss: 0.0362 - average_loss: 0.0332 - vit_accuracy: 0.9890 - model0_accuracy: 0.9899 - average_accuracy: 0.9910 - val_loss: 0.1669 - val_vit_loss: 0.0549 - val_model0_loss: 0.0586 - val_average_loss: 0.0546 - val_vit_accuracy: 0.9838 - val_model0_accuracy: 0.9838 - val_average_accuracy: 0.9835 - lr: 9.2160e-05\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 9.216e-05.\n",
            "Epoch 7/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1036 - vit_loss: 0.0402 - model0_loss: 0.0361 - average_loss: 0.0333 - vit_accuracy: 0.9890 - model0_accuracy: 0.9905 - average_accuracy: 0.9909\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 4.608000017469749e-05.\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.1036 - vit_loss: 0.0402 - model0_loss: 0.0361 - average_loss: 0.0333 - vit_accuracy: 0.9890 - model0_accuracy: 0.9905 - average_accuracy: 0.9909 - val_loss: 0.1630 - val_vit_loss: 0.0534 - val_model0_loss: 0.0575 - val_average_loss: 0.0533 - val_vit_accuracy: 0.9834 - val_model0_accuracy: 0.9844 - val_average_accuracy: 0.9844 - lr: 9.2160e-05\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 9.216e-05.\n",
            "Epoch 8/50\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0994 - vit_loss: 0.0368 - model0_loss: 0.0353 - average_loss: 0.0319 - vit_accuracy: 0.9898 - model0_accuracy: 0.9903 - average_accuracy: 0.9916 - val_loss: 0.1633 - val_vit_loss: 0.0538 - val_model0_loss: 0.0573 - val_average_loss: 0.0534 - val_vit_accuracy: 0.9834 - val_model0_accuracy: 0.9835 - val_average_accuracy: 0.9841 - lr: 9.2160e-05\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 8.847359999999999e-05.\n",
            "Epoch 9/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0981 - vit_loss: 0.0370 - model0_loss: 0.0342 - average_loss: 0.0316 - vit_accuracy: 0.9897 - model0_accuracy: 0.9905 - average_accuracy: 0.9915\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.423680002219044e-05.\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0981 - vit_loss: 0.0370 - model0_loss: 0.0342 - average_loss: 0.0316 - vit_accuracy: 0.9897 - model0_accuracy: 0.9905 - average_accuracy: 0.9915 - val_loss: 0.1661 - val_vit_loss: 0.0543 - val_model0_loss: 0.0588 - val_average_loss: 0.0542 - val_vit_accuracy: 0.9836 - val_model0_accuracy: 0.9840 - val_average_accuracy: 0.9839 - lr: 8.8474e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 8.847359999999999e-05.\n",
            "Epoch 10/50\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0973 - vit_loss: 0.0366 - model0_loss: 0.0344 - average_loss: 0.0312 - vit_accuracy: 0.9900 - model0_accuracy: 0.9909 - average_accuracy: 0.9916 - val_loss: 0.1650 - val_vit_loss: 0.0546 - val_model0_loss: 0.0578 - val_average_loss: 0.0540 - val_vit_accuracy: 0.9841 - val_model0_accuracy: 0.9840 - val_average_accuracy: 0.9844 - lr: 8.8474e-05\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 8.847359999999999e-05.\n",
            "Epoch 11/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0964 - vit_loss: 0.0361 - model0_loss: 0.0344 - average_loss: 0.0308 - vit_accuracy: 0.9894 - model0_accuracy: 0.9908 - average_accuracy: 0.9918\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 4.423680002219044e-05.\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0964 - vit_loss: 0.0361 - model0_loss: 0.0344 - average_loss: 0.0308 - vit_accuracy: 0.9894 - model0_accuracy: 0.9908 - average_accuracy: 0.9918 - val_loss: 0.1638 - val_vit_loss: 0.0540 - val_model0_loss: 0.0575 - val_average_loss: 0.0536 - val_vit_accuracy: 0.9840 - val_model0_accuracy: 0.9845 - val_average_accuracy: 0.9849 - lr: 8.8474e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 8.847359999999999e-05.\n",
            "Epoch 12/50\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0900 - vit_loss: 0.0337 - model0_loss: 0.0318 - average_loss: 0.0289 - vit_accuracy: 0.9904 - model0_accuracy: 0.9917 - average_accuracy: 0.9924 - val_loss: 0.1655 - val_vit_loss: 0.0549 - val_model0_loss: 0.0578 - val_average_loss: 0.0542 - val_vit_accuracy: 0.9841 - val_model0_accuracy: 0.9841 - val_average_accuracy: 0.9850 - lr: 8.8474e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 8.493465599999999e-05.\n",
            "Epoch 13/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0915 - vit_loss: 0.0347 - model0_loss: 0.0320 - average_loss: 0.0294 - vit_accuracy: 0.9898 - model0_accuracy: 0.9909 - average_accuracy: 0.9920\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 4.2467327148187906e-05.\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0915 - vit_loss: 0.0347 - model0_loss: 0.0320 - average_loss: 0.0294 - vit_accuracy: 0.9898 - model0_accuracy: 0.9909 - average_accuracy: 0.9920 - val_loss: 0.1653 - val_vit_loss: 0.0545 - val_model0_loss: 0.0580 - val_average_loss: 0.0541 - val_vit_accuracy: 0.9835 - val_model0_accuracy: 0.9840 - val_average_accuracy: 0.9843 - lr: 8.4935e-05\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 8.493465599999999e-05.\n",
            "Epoch 14/50\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0887 - vit_loss: 0.0334 - model0_loss: 0.0314 - average_loss: 0.0284 - vit_accuracy: 0.9909 - model0_accuracy: 0.9910 - average_accuracy: 0.9921 - val_loss: 0.1637 - val_vit_loss: 0.0539 - val_model0_loss: 0.0577 - val_average_loss: 0.0535 - val_vit_accuracy: 0.9846 - val_model0_accuracy: 0.9841 - val_average_accuracy: 0.9853 - lr: 8.4935e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 8.493465599999999e-05.\n",
            "Epoch 15/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0866 - vit_loss: 0.0325 - model0_loss: 0.0307 - average_loss: 0.0277 - vit_accuracy: 0.9909 - model0_accuracy: 0.9913 - average_accuracy: 0.9926\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.2467327148187906e-05.\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0866 - vit_loss: 0.0325 - model0_loss: 0.0307 - average_loss: 0.0277 - vit_accuracy: 0.9909 - model0_accuracy: 0.9913 - average_accuracy: 0.9926 - val_loss: 0.1670 - val_vit_loss: 0.0554 - val_model0_loss: 0.0586 - val_average_loss: 0.0546 - val_vit_accuracy: 0.9837 - val_model0_accuracy: 0.9847 - val_average_accuracy: 0.9844 - lr: 8.4935e-05\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 8.493465599999999e-05.\n",
            "Epoch 16/50\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0856 - vit_loss: 0.0322 - model0_loss: 0.0306 - average_loss: 0.0273 - vit_accuracy: 0.9905 - model0_accuracy: 0.9916 - average_accuracy: 0.9924 - val_loss: 0.1653 - val_vit_loss: 0.0545 - val_model0_loss: 0.0582 - val_average_loss: 0.0540 - val_vit_accuracy: 0.9841 - val_model0_accuracy: 0.9846 - val_average_accuracy: 0.9844 - lr: 8.4935e-05\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 8.153726975999998e-05.\n",
            "Epoch 17/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0828 - vit_loss: 0.0312 - model0_loss: 0.0292 - average_loss: 0.0265 - vit_accuracy: 0.9911 - model0_accuracy: 0.9916 - average_accuracy: 0.9930\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 4.076863478985615e-05.\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0828 - vit_loss: 0.0312 - model0_loss: 0.0292 - average_loss: 0.0265 - vit_accuracy: 0.9911 - model0_accuracy: 0.9916 - average_accuracy: 0.9930 - val_loss: 0.1658 - val_vit_loss: 0.0546 - val_model0_loss: 0.0583 - val_average_loss: 0.0542 - val_vit_accuracy: 0.9842 - val_model0_accuracy: 0.9844 - val_average_accuracy: 0.9845 - lr: 8.1537e-05\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 8.153726975999998e-05.\n",
            "Epoch 18/50\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0787 - vit_loss: 0.0297 - model0_loss: 0.0276 - average_loss: 0.0253 - vit_accuracy: 0.9913 - model0_accuracy: 0.9925 - average_accuracy: 0.9935 - val_loss: 0.1673 - val_vit_loss: 0.0550 - val_model0_loss: 0.0589 - val_average_loss: 0.0547 - val_vit_accuracy: 0.9845 - val_model0_accuracy: 0.9847 - val_average_accuracy: 0.9843 - lr: 8.1537e-05\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 8.153726975999998e-05.\n",
            "Epoch 19/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0802 - vit_loss: 0.0300 - model0_loss: 0.0287 - average_loss: 0.0256 - vit_accuracy: 0.9916 - model0_accuracy: 0.9920 - average_accuracy: 0.9931\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.076863478985615e-05.\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0802 - vit_loss: 0.0300 - model0_loss: 0.0287 - average_loss: 0.0256 - vit_accuracy: 0.9916 - model0_accuracy: 0.9920 - average_accuracy: 0.9931 - val_loss: 0.1665 - val_vit_loss: 0.0552 - val_model0_loss: 0.0583 - val_average_loss: 0.0545 - val_vit_accuracy: 0.9840 - val_model0_accuracy: 0.9847 - val_average_accuracy: 0.9845 - lr: 8.1537e-05\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 8.153726975999998e-05.\n",
            "Epoch 20/50\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0773 - vit_loss: 0.0296 - model0_loss: 0.0269 - average_loss: 0.0249 - vit_accuracy: 0.9915 - model0_accuracy: 0.9927 - average_accuracy: 0.9937 - val_loss: 0.1690 - val_vit_loss: 0.0557 - val_model0_loss: 0.0594 - val_average_loss: 0.0553 - val_vit_accuracy: 0.9848 - val_model0_accuracy: 0.9851 - val_average_accuracy: 0.9850 - lr: 8.1537e-05\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 7.827577896959998e-05.\n",
            "Epoch 21/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0775 - vit_loss: 0.0296 - model0_loss: 0.0266 - average_loss: 0.0251 - vit_accuracy: 0.9920 - model0_accuracy: 0.9932 - average_accuracy: 0.9938\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 3.913788896170445e-05.\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0775 - vit_loss: 0.0296 - model0_loss: 0.0266 - average_loss: 0.0251 - vit_accuracy: 0.9920 - model0_accuracy: 0.9932 - average_accuracy: 0.9938 - val_loss: 0.1673 - val_vit_loss: 0.0558 - val_model0_loss: 0.0585 - val_average_loss: 0.0547 - val_vit_accuracy: 0.9834 - val_model0_accuracy: 0.9844 - val_average_accuracy: 0.9846 - lr: 7.8276e-05\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 7.827577896959998e-05.\n",
            "Epoch 22/50\n",
            "625/625 [==============================] - 786s 1s/step - loss: 0.0748 - vit_loss: 0.0274 - model0_loss: 0.0270 - average_loss: 0.0239 - vit_accuracy: 0.9924 - model0_accuracy: 0.9927 - average_accuracy: 0.9936 - val_loss: 0.1704 - val_vit_loss: 0.0561 - val_model0_loss: 0.0601 - val_average_loss: 0.0556 - val_vit_accuracy: 0.9846 - val_model0_accuracy: 0.9844 - val_average_accuracy: 0.9849 - lr: 7.8276e-05\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 7.827577896959998e-05.\n",
            "Epoch 23/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0731 - vit_loss: 0.0278 - model0_loss: 0.0252 - average_loss: 0.0236 - vit_accuracy: 0.9922 - model0_accuracy: 0.9928 - average_accuracy: 0.9940\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 3.913788896170445e-05.\n",
            "625/625 [==============================] - 786s 1s/step - loss: 0.0731 - vit_loss: 0.0278 - model0_loss: 0.0252 - average_loss: 0.0236 - vit_accuracy: 0.9922 - model0_accuracy: 0.9928 - average_accuracy: 0.9940 - val_loss: 0.1674 - val_vit_loss: 0.0551 - val_model0_loss: 0.0590 - val_average_loss: 0.0547 - val_vit_accuracy: 0.9847 - val_model0_accuracy: 0.9843 - val_average_accuracy: 0.9851 - lr: 7.8276e-05\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 7.827577896959998e-05.\n",
            "Epoch 24/50\n",
            "625/625 [==============================] - 786s 1s/step - loss: 0.0731 - vit_loss: 0.0269 - model0_loss: 0.0260 - average_loss: 0.0234 - vit_accuracy: 0.9924 - model0_accuracy: 0.9927 - average_accuracy: 0.9937 - val_loss: 0.1698 - val_vit_loss: 0.0560 - val_model0_loss: 0.0599 - val_average_loss: 0.0554 - val_vit_accuracy: 0.9845 - val_model0_accuracy: 0.9839 - val_average_accuracy: 0.9845 - lr: 7.8276e-05\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 7.514474781081598e-05.\n",
            "Epoch 25/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0719 - vit_loss: 0.0275 - model0_loss: 0.0249 - average_loss: 0.0231 - vit_accuracy: 0.9924 - model0_accuracy: 0.9934 - average_accuracy: 0.9942\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.75723720935639e-05.\n",
            "625/625 [==============================] - 786s 1s/step - loss: 0.0719 - vit_loss: 0.0275 - model0_loss: 0.0249 - average_loss: 0.0231 - vit_accuracy: 0.9924 - model0_accuracy: 0.9934 - average_accuracy: 0.9942 - val_loss: 0.1699 - val_vit_loss: 0.0563 - val_model0_loss: 0.0597 - val_average_loss: 0.0555 - val_vit_accuracy: 0.9847 - val_model0_accuracy: 0.9848 - val_average_accuracy: 0.9852 - lr: 7.5145e-05\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 7.514474781081598e-05.\n",
            "Epoch 26/50\n",
            "625/625 [==============================] - 786s 1s/step - loss: 0.0711 - vit_loss: 0.0263 - model0_loss: 0.0249 - average_loss: 0.0229 - vit_accuracy: 0.9924 - model0_accuracy: 0.9931 - average_accuracy: 0.9942 - val_loss: 0.1687 - val_vit_loss: 0.0556 - val_model0_loss: 0.0596 - val_average_loss: 0.0551 - val_vit_accuracy: 0.9840 - val_model0_accuracy: 0.9842 - val_average_accuracy: 0.9848 - lr: 7.5145e-05\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 7.514474781081598e-05.\n",
            "Epoch 27/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0668 - vit_loss: 0.0257 - model0_loss: 0.0233 - average_loss: 0.0215 - vit_accuracy: 0.9930 - model0_accuracy: 0.9936 - average_accuracy: 0.9947\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.75723720935639e-05.\n",
            "625/625 [==============================] - 786s 1s/step - loss: 0.0668 - vit_loss: 0.0257 - model0_loss: 0.0233 - average_loss: 0.0215 - vit_accuracy: 0.9930 - model0_accuracy: 0.9936 - average_accuracy: 0.9947 - val_loss: 0.1702 - val_vit_loss: 0.0560 - val_model0_loss: 0.0603 - val_average_loss: 0.0555 - val_vit_accuracy: 0.9846 - val_model0_accuracy: 0.9850 - val_average_accuracy: 0.9849 - lr: 7.5145e-05\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 7.514474781081598e-05.\n",
            "Epoch 28/50\n",
            "625/625 [==============================] - 786s 1s/step - loss: 0.0660 - vit_loss: 0.0247 - model0_loss: 0.0232 - average_loss: 0.0212 - vit_accuracy: 0.9932 - model0_accuracy: 0.9940 - average_accuracy: 0.9951 - val_loss: 0.1739 - val_vit_loss: 0.0577 - val_model0_loss: 0.0611 - val_average_loss: 0.0568 - val_vit_accuracy: 0.9838 - val_model0_accuracy: 0.9848 - val_average_accuracy: 0.9842 - lr: 7.5145e-05\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 7.213895789838334e-05.\n",
            "Epoch 29/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0673 - vit_loss: 0.0252 - model0_loss: 0.0234 - average_loss: 0.0217 - vit_accuracy: 0.9925 - model0_accuracy: 0.9935 - average_accuracy: 0.9947\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 3.606947939260863e-05.\n",
            "625/625 [==============================] - 786s 1s/step - loss: 0.0673 - vit_loss: 0.0252 - model0_loss: 0.0234 - average_loss: 0.0217 - vit_accuracy: 0.9925 - model0_accuracy: 0.9935 - average_accuracy: 0.9947 - val_loss: 0.1723 - val_vit_loss: 0.0571 - val_model0_loss: 0.0606 - val_average_loss: 0.0563 - val_vit_accuracy: 0.9842 - val_model0_accuracy: 0.9839 - val_average_accuracy: 0.9849 - lr: 7.2139e-05\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 7.213895789838334e-05.\n",
            "Epoch 30/50\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0654 - vit_loss: 0.0246 - model0_loss: 0.0228 - average_loss: 0.0210 - vit_accuracy: 0.9935 - model0_accuracy: 0.9938 - average_accuracy: 0.9947 - val_loss: 0.1749 - val_vit_loss: 0.0582 - val_model0_loss: 0.0613 - val_average_loss: 0.0572 - val_vit_accuracy: 0.9838 - val_model0_accuracy: 0.9848 - val_average_accuracy: 0.9854 - lr: 7.2139e-05\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 7.213895789838334e-05.\n",
            "Epoch 31/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0629 - vit_loss: 0.0229 - model0_loss: 0.0225 - average_loss: 0.0202 - vit_accuracy: 0.9940 - model0_accuracy: 0.9942 - average_accuracy: 0.9954\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 3.606947939260863e-05.\n",
            "625/625 [==============================] - 785s 1s/step - loss: 0.0629 - vit_loss: 0.0229 - model0_loss: 0.0225 - average_loss: 0.0202 - vit_accuracy: 0.9940 - model0_accuracy: 0.9942 - average_accuracy: 0.9954 - val_loss: 0.1739 - val_vit_loss: 0.0579 - val_model0_loss: 0.0609 - val_average_loss: 0.0568 - val_vit_accuracy: 0.9837 - val_model0_accuracy: 0.9843 - val_average_accuracy: 0.9845 - lr: 7.2139e-05\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 7.213895789838334e-05.\n",
            "Epoch 32/50\n",
            "625/625 [==============================] - 786s 1s/step - loss: 0.0622 - vit_loss: 0.0233 - model0_loss: 0.0218 - average_loss: 0.0200 - vit_accuracy: 0.9934 - model0_accuracy: 0.9942 - average_accuracy: 0.9951 - val_loss: 0.1752 - val_vit_loss: 0.0581 - val_model0_loss: 0.0617 - val_average_loss: 0.0572 - val_vit_accuracy: 0.9844 - val_model0_accuracy: 0.9848 - val_average_accuracy: 0.9854 - lr: 7.2139e-05\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 6.9253399582448e-05.\n",
            "Epoch 33/50\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0600 - vit_loss: 0.0229 - model0_loss: 0.0210 - average_loss: 0.0193 - vit_accuracy: 0.9938 - model0_accuracy: 0.9941 - average_accuracy: 0.9954\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.462670065346174e-05.\n",
            "625/625 [==============================] - 786s 1s/step - loss: 0.0600 - vit_loss: 0.0229 - model0_loss: 0.0210 - average_loss: 0.0193 - vit_accuracy: 0.9938 - model0_accuracy: 0.9941 - average_accuracy: 0.9954 - val_loss: 0.1731 - val_vit_loss: 0.0578 - val_model0_loss: 0.0606 - val_average_loss: 0.0566 - val_vit_accuracy: 0.9843 - val_model0_accuracy: 0.9855 - val_average_accuracy: 0.9851 - lr: 6.9253e-05\n"
          ]
        }
      ],
      "source": [
        "optimizer_adamax =Adamax(learning_rate=0.001)\n",
        "lossWeights = {'model0':0.75,'vit':0.25,'average':2.0}\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "model_final.compile( optimizer=optimizer_adamax, metrics=[\"accuracy\"],loss={'model0':loss,'vit':loss,'average':loss},loss_weights=lossWeights)\n",
        "history = model_final.fit(train_data, epochs=50,validation_data=valid_data,batch_size=64,callbacks=[mycallback],workers=8)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Em_vCIvsWgol",
        "ra0K4ju7uU-P",
        "9iJKlP4OUxTP",
        "wMKcSVz1tItl",
        "8pQrnYlUtIto",
        "z9KveLojtItq",
        "ZduIbfCytItr",
        "FcOq3beitItv",
        "gaR5YSPftItw",
        "LIqpvjSCiHhn",
        "B79pvsRbirs0",
        "c5S6rz0Aogt1",
        "DJy1pvBqovBA",
        "p-JmQby_jm2a",
        "nyNvEJ_dL0v2",
        "uSUFup2gvCcT",
        "ZYhlM_Jro7Ne",
        "POAYJuSo3kSq",
        "4Ri7M2T1F962",
        "KcRHVhEBGLkn",
        "Dlglbt7zsoj8",
        "BMj_1QprDntK",
        "X-9rxtO4Dba0"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "environment": {
      "name": "tf2-gpu.2-4.m61",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}